# Milestone v1.3: GDELT Intelligence

**Status:** ✅ SHIPPED 2026-01-11
**Phases:** 19-27
**Total Plans:** 24

## Overview

Maximize value from free BigQuery GDELT data (61 fields vs current 4) - rebuild intelligence pipeline around rich GDELT signals to reduce LLM costs and improve risk scoring accuracy. Includes scoring system refinements to properly handle both positive and negative event impacts, entity resolution for multi-source tracking, pattern discovery with graph analytics, and complete GCP serverless infrastructure deployment.

## Phases

### Phase 19: GDELT Events Enrichment

**Goal**: Migrate from 4 basic fields to all 61 GDELT BigQuery fields (quotations, themes, tone, images, Goldstein scale, counts)
**Depends on**: Phase 18 (GCP-Native Pipeline Migration)
**Research**: Likely (GDELT field schema, quotations parsing, Goldstein scale interpretation)
**Plans**: 1 plan (partial implementation)

Plans:
- [x] 19-01: GDELT Fields Expansion

**Details:**
Initial exploration of GDELT's 61-field schema. Identified key fields for risk scoring enhancement: GoldsteinScale (-10 to +10 conflict/cooperation), AvgTone (sentiment), themes (2,300+ categories), QuadClass (material/verbal conflict/cooperation), NumMentions (article count), Actor1/Actor2 codes, geographic coordinates. Foundation for subsequent phases.

---

### Phase 20: GKG Integration

**Goal**: Integrate GDELT Global Knowledge Graph for richer entity extraction, location mapping, theme categorization, and people/org tracking
**Depends on**: Phase 19
**Research**: Likely (GKG table schema, GCAM scores, entity relationships)
**Plans**: 2 plans

Plans:
- [x] 20-01: GKG Data Fetching
- [x] 20-02: GKG Entity and Theme Parsing

**Details:**
Integrated GDELT GKG (Global Knowledge Graph) for enhanced entity extraction. Implemented BigQuery federation to query GKG by DocumentIdentifier, parsing V2Persons, V2Organizations, V2Locations, and V2Themes from raw GKG strings. Jaro-Winkler 0.85 threshold for entity deduplication. GKG entities supplement (not replace) LLM extraction with source attribution metadata ('llm' vs 'gkg'). Quotations and GCAM emotional dimensions kept raw for future parsing.

---

### Phase 21: Mentions Tracking

**Goal**: Track narrative spread by monitoring how events are mentioned across articles over time for early warning signals
**Depends on**: Phase 20
**Research**: Complete
**Plans**: 3/3 complete
**Status**: Complete

Plans:
- [x] 21-01: Mentions tracking infrastructure (PostgreSQL spike model + BigQuery service)
- [x] 21-02: TDD spike detection logic
- [x] 21-03: Mention tracker Cloud Function deployment

**Details:**
Implemented mention tracking with PostgreSQL EventMentionSpike model and BigQuery service layer. 7-day rolling window baseline with ROWS BETWEEN 7 PRECEDING AND 1 PRECEDING (excludes current day). Z-score spike detection with configurable threshold (default 2.0). Event ID as CharField for polyglot architecture. Cloud Function deployed for serverless spike detection. 30-day lookback window for efficient mention queries.

---

### Phase 22: Data Source Architecture

**Goal**: Rebuild data source architecture with scalable adapter pattern (GDELT-first, plugin system for future integrations)
**Depends on**: Phase 21
**Research**: Unlikely (internal refactoring using established patterns from Phase 14.3)
**Plans**: 1 plan

Plans:
- [x] 22-01: Adapter Foundation (DataSourceAdapter ABC, AdapterRegistry)

**Details:**
Created DataSourceAdapter abstract base class with standardized interface: validate(), transform(), publish_events(). Convention-based discovery ({source}_adapter.py → {Source}Adapter class). Separate validate() from transform() for partial success publishing. In-memory health tracking (not persistent) for lightweight observability. Concrete publish_events() helper prevents code duplication across adapters. Foundation for Phase 24 multi-source integration.

---

### Phase 23: Intelligence Pipeline Rebuild

**Goal**: Redesign intelligence pipeline to use GDELT tone/sentiment scores, themes, and quote analysis as primary risk signals
**Depends on**: Phase 22
**Research**: Likely (GDELT-based risk scoring methodologies)
**Plans**: 2 plans

Plans:
- [x] 23-01: GDELT Quantitative Scorer
- [x] 23-02: Hybrid GDELT + LLM Scoring

**Details:**
Rebuilt intelligence pipeline with composite risk scoring. GdeltQuantitativeScorer uses MinMaxScaler with codebook ranges (not data-fitted) for stable normalization. Inverted Goldstein scale and tone (negative values = higher risk) for intuitive scoring. Default weights: goldstein=0.35, tone=0.25, themes=0.25, intensity=0.15. Theme presence scored categorically (1=60, 2=80, 3+=100). Theme intensity by frequency (0=20, 1-2=50, 3-5=75, 6+=100). Handles missing GKG data with neutral score (50). Hybrid approach combines GDELT quantitative signals with LLM context analysis.

---

### Phase 24: BigQuery Public Datasets

**Goal**: Integrate Google Trends, SEC EDGAR, and World Bank data via BigQuery public datasets for multi-source intelligence correlation
**Depends on**: Phase 23
**Plans**: 3 plans complete
**Status**: Complete

Plans:
- [x] 24-01: Entity Resolution Foundation (Splink + canonical entity registry)
- [x] 24-02: BigQuery Adapters (Google Trends, SEC EDGAR, World Bank)
- [x] 24-03: API Integration & Entity Linking

**Details:**
Complete multi-source entity-centric intelligence pipeline. Splink-based entity resolution with Tier 1 exact match (0.95 confidence) and Tier 2 probabilistic matching (0.85 threshold). Blocking rules use first 3 chars + country_code + entity_type for O(n) performance. CanonicalEntity and EntityAlias models for deduplication. BigQuery adapters for Google Trends international_top_terms, World Bank WDI indicators, and SEC EDGAR (stub pending schema discovery). Event type mapping: Google Trends=social, World Bank=economic, SEC EDGAR=regulatory. Partition filtering for cost optimization (1TB/month free tier). Entity linking at publish time (not query time) for performance. GET /api/entities/{id}/sources groups events by source. Stable event ID formats: gt-{date}-{term}, wb-{code}-{indicator}-{year}, sec-{filing_id}.

---

### Phase 25: Update System to Follow Platform Design

**Goal**: Update the system to roughly follow the design in docs/venezuela_risk_platform_design.md
**Depends on**: Phase 24
**Plans**: 2 plans complete
**Status**: Complete

Plans:
- [x] 25-01: Refactor severity and risk scoring services
- [x] 25-02: Update adapters to use new severity and risk scoring

**Details:**
Aligned implementation with canonical event model, severity assignment (P1-P4), and composite risk scoring architecture from platform design document. Refactored SeverityClassifier and CompositeRiskScorer to match design specifications. Updated all adapters (GDELT, ReliefWeb, FRED, UN Comtrade, World Bank, Google Trends, SEC EDGAR) to use new scoring services. P1-P4 severity levels follow NCISS-style classification. Composite risk scoring integrates Goldstein scale, tone, themes, and intensity dimensions.

---

### Phase 26: GKG Theme Population, Entity Relationship Graphs, Event Lineage Tracking

**Goal**: GKG theme population, entity relationship graphs, event lineage tracking
**Depends on**: Phase 25
**Plans**: 4/4 plans complete
**Status**: Complete
**Completed**: 2026-01-10

Plans:
- [x] 26-01: Backend graph data service with community detection
- [x] 26-02: Interactive entity relationship graph visualization with Reagraph
- [x] 26-03: Camera auto-focus and edge narratives for pattern discovery
- [x] 26-04: GKG theme filtering and event lineage tracking

**Details:**
Backend graph service with Louvain community detection (Node.js subprocess for Graphology) and co-occurrence edge weighting (threshold default 3). Undirected graph edges for symmetric relationships. Time range default 30 days for recency vs data volume balance. Interactive WebGL graph visualization with Reagraph showing risk-based node colors, directional weighted edges, and click navigation. Camera auto-focus to largest high-risk cluster. LLM-generated edge narratives explaining entity connections through causal chains (Claude API). GKG theme filtering for activity-specific networks: sanctions (WB_1065_SANCTION), trade (WB_634_EXPORT, WB_638_IMPORT), political (USPEC_POLICY_POLITICAL), energy (WB_1275_PETROLEUM, ENV_ENERGY), adversarial (TAX_FNCACT_ADVERSARY). Temporal event lineage visualization showing cascade effects and escalation detection. **Phase complete** - full pattern discovery system operational.

---

### Phase 27: Small-Scale End-to-End Pipeline Test in GCP

**Goal**: Small-scale end-to-end pipeline test in GCP
**Depends on**: Phase 26
**Plans**: 4/4 plans complete
**Status**: Complete
**Completed**: 2026-01-11

Plans:
- [x] 27-01: GCP Infrastructure Deployment
- [x] 27-02: Small-Scale Data Ingestion Test
- [x] 27-03: End-to-End Pipeline Validation
- [x] 27-04: Processing Pipeline Configuration and Validation

**Details:**
Complete event-driven processing pipeline configured and validated. Deployed 7 Cloud Functions (GDELT sync, ReliefWeb, FRED, UN Comtrade, World Bank, Google Trends, SEC EDGAR) with 512MB-900MB memory allocation and OIDC authentication. Cloud Run API deployed (2Gi memory) with internal endpoints (/api/internal/process-event, /api/internal/enqueue-intelligence). Pub/Sub push subscriptions wired to Cloud Run internal endpoints (<1s latency). Cloud Tasks queue created (rate-limits-queue) with rate limiting (100 dispatches/s, 500 concurrent). IAM permissions configured: Cloud Run service account requires cloudtasks.enqueuer and iam.serviceAccountUser roles. Environment-based GCP_PROJECT_ID configuration for multi-environment portability. Pipeline orchestration functional: Cloud Scheduler → Cloud Functions → BigQuery → Pub/Sub → Cloud Run → Cloud Tasks. Standalone gdelt_sync function with direct BigQuery query (no Django dependencies). Infrastructure validated successfully - operational tuning (LLM timeouts) deferred. **Phase complete** - full GCP deployment ready for production.

---

## Milestone Summary

**Key Decisions:**

- GDELT native BigQuery dataset: 4x event capacity, 15x richer fields, eliminates custom ingestion infrastructure (Phase 19-20)
- Splink entity resolution: Probabilistic matching enables multi-source entity linking, open-source alternative to commercial services (Phase 24)
- Node.js subprocess for Louvain: No Python equivalent for Graphology, subprocess pattern enables best-of-breed graph algorithms (Phase 26)
- Composite risk scoring with GDELT signals: Goldstein scale, AvgTone, themes, intensity provide quantitative foundation reducing LLM dependency and cost (Phase 23)
- P1-P4 severity classification: Follows industry standard (NCISS-style) for event impact classification (Phase 25)
- GCP-native serverless orchestration: Event-driven pipeline with automatic scaling, eliminated Celery/Redis complexity (Phase 27)

**Issues Resolved:**

- Entity duplication across data sources - resolved with Splink canonical entity registry
- Risk scoring over-reliance on LLM - resolved with GDELT quantitative signals
- Manual infrastructure deployment - resolved with GCP serverless automation
- Pattern discovery limited to individual entities - resolved with graph analytics and community detection
- Narrative amplification detection missing - resolved with mentions spike detection

**Issues Deferred:**

- LLM timeout tuning for production workloads (operational configuration)
- Phase 15-02 correlation visualization UI (backend complete in v1.2)
- SEC EDGAR full implementation (adapter stub created, schema discovery needed)

**Technical Debt Incurred:**

- Node.js subprocess for Graphology Louvain (Python-JS bridge, acceptable for best-of-breed algorithm)
- Some GKG fields kept raw (quotations, GCAM) pending future parsing enhancement

---

_For current project status, see .planning/ROADMAP.md_
