---
phase: 22-data-source-architecture
plan: 03
type: execute
---

<objective>
Migrate Cloud Function to use new adapter architecture.

Purpose: Update the serverless GDELT sync Cloud Function to use GdeltAdapter instead of inline logic, completing the architecture migration. This proves the adapter pattern works in production context.

Output: Updated Cloud Function using GdeltAdapter, verified to produce identical behavior.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-data-source-architecture/22-CONTEXT.md
@.planning/phases/22-data-source-architecture/22-01-SUMMARY.md
@.planning/phases/22-data-source-architecture/22-02-SUMMARY.md
@functions/gdelt_sync/main.py

**Tech stack available from 22-01 and 22-02:**
- GdeltAdapter with fetch/transform/validate methods
- AdapterRegistry for adapter discovery
- DataSourceAdapter.publish_events() for Pub/Sub integration

**Established patterns:**
- Phase 18: Cloud Functions Gen2 with HTTP triggers
- Phase 18: Standalone functions with no Django dependencies
- Phase 18: Pub/Sub event publishing for downstream processing

**Constraining decisions:**
- Phase 18: 512MB-900MB memory allocation based on complexity
- Phase 18: OIDC authentication for Cloud Scheduler
- Phase 18: 100% business logic reuse (only orchestration changes)

**From 22-CONTEXT.md essential requirements:**
- Zero behavior change for GDELT (same data, frequency, results)
- Full observability (health metrics, logging)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update Cloud Function to use GdeltAdapter</name>
  <files>functions/gdelt_sync/main.py, functions/gdelt_sync/requirements.txt</files>
  <action>
Replace inline GDELT logic with GdeltAdapter usage.

**File: functions/gdelt_sync/main.py**

Refactor sync_gdelt_events function:

**Remove:**
- GDELTBigQueryService class (replaced by GdeltAdapter.fetch)
- Inline transform logic (replaced by GdeltAdapter.transform)
- Inline validation logic (replaced by GdeltAdapter.validate)

**Replace with:**
```python
# Add to imports (Cloud Functions need to import from backend code)
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'backend'))

from data_pipeline.adapters.gdelt_adapter import GdeltAdapter
from datetime import datetime, timedelta

@functions_framework.http
def sync_gdelt_events(request: Request):
    """HTTP Cloud Function using GdeltAdapter."""
    try:
        # Parse request
        request_json = request.get_json(silent=True) or {}
        lookback_minutes = request_json.get('lookback_minutes', 15)

        logger.info(f"Starting GDELT sync via GdeltAdapter (lookback: {lookback_minutes}m)")

        # Initialize adapter
        adapter = GdeltAdapter()

        # Time range
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(minutes=lookback_minutes)

        # Fetch raw events
        raw_events = adapter.fetch(start_time, end_time, limit=1000)
        logger.info(f"Fetched {len(raw_events)} events from GDELT")

        # Transform to BigQuery schema
        bq_events = adapter.transform(raw_events)

        # Validate and filter
        valid_events = []
        events_skipped = 0
        for event in bq_events:
            is_valid, error = adapter.validate(event)
            if is_valid:
                valid_events.append(event)
            else:
                logger.debug(f"Skipping invalid event {event.id}: {error}")
                events_skipped += 1

        # Publish to Pub/Sub for downstream processing
        if valid_events:
            result = adapter.publish_events(valid_events)
            logger.info(
                f"Published {result['published']} events, {result['failed']} failed"
            )

        return {
            'events_created': len(valid_events),
            'events_skipped': events_skipped,
            'events_fetched': len(raw_events)
        }, 200

    except Exception as e:
        logger.error(f"GDELT sync failed: {e}", exc_info=True)
        return {'error': str(e)}, 500
```

**Key changes:**
- Use adapter.fetch() instead of GDELTBigQueryService
- Use adapter.transform() instead of inline mapping
- Use adapter.validate() instead of inline duplicate checking
- Use adapter.publish_events() instead of direct PubSub client calls
- Preserve exact same logging, error handling, response format

**File: functions/gdelt_sync/requirements.txt**

Ensure backend code is accessible (Cloud Functions will deploy with backend/ in same package). No new dependencies needed - GdeltAdapter reuses existing BigQuery/GKG services.

The key insight: Cloud Function becomes thin orchestration layer. All business logic now lives in GdeltAdapter where it's testable and reusable.
  </action>
  <verify>
# Local test (simulate Cloud Function invocation)
cd functions/gdelt_sync
python -c "
import sys
sys.path.insert(0, '../../backend')
from data_pipeline.adapters.gdelt_adapter import GdeltAdapter
from datetime import datetime, timedelta

adapter = GdeltAdapter()
end_time = datetime.utcnow()
start_time = end_time - timedelta(minutes=15)

raw = adapter.fetch(start_time, end_time, limit=10)
print(f'Fetched {len(raw)} events')

bq = adapter.transform(raw)
print(f'Transformed {len(bq)} events')

valid, error = adapter.validate(bq[0]) if bq else (False, 'no events')
print(f'Validation: {valid}, {error}')
"

Should fetch/transform/validate successfully.
  </verify>
  <done>
- Cloud Function refactored to use GdeltAdapter
- GDELTBigQueryService class removed
- Inline transform/validate logic removed
- Function uses adapter.fetch/transform/validate/publish_events
- Response format unchanged ({events_created, events_skipped, events_fetched})
- Logging preserved at same verbosity
- Error handling unchanged
- Local test confirms adapter integration works
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Refactored gdelt_sync Cloud Function using GdeltAdapter architecture</what-built>
  <how-to-verify>
Manual verification steps to confirm behavior unchanged:

**1. Review code changes:**
```bash
cd functions/gdelt_sync
git diff main.py
```

Confirm:
- GdeltAdapter imported and instantiated
- fetch/transform/validate methods called
- No inline GDELT logic remains
- Response format identical to previous version

**2. Check adapter integration locally:**
```bash
cd functions/gdelt_sync
python -c "
import sys
sys.path.insert(0, '../../backend')
import os
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'venezuelawatch.settings')

import django
django.setup()

from data_pipeline.adapters.gdelt_adapter import GdeltAdapter
from datetime import datetime, timedelta

adapter = GdeltAdapter()
end_time = datetime.utcnow()
start_time = end_time - timedelta(hours=1)

# Fetch a few events
raw = adapter.fetch(start_time, end_time, limit=5)
print(f'✓ Fetched {len(raw)} events')

# Transform
bq = adapter.transform(raw)
print(f'✓ Transformed to {len(bq)} BigQuery events')

# Validate first event
if bq:
    valid, error = adapter.validate(bq[0])
    print(f'✓ Validation: valid={valid}, error={error}')
    print(f'✓ Event ID: {bq[0].id}')
    print(f'✓ Has GKG: {\"gkg\" in bq[0].metadata}')
else:
    print('⚠ No events in 1-hour window (may be normal)')
"
```

Expected output:
- ✓ Fetched N events (N > 0 usually, but may be 0 if quiet period)
- ✓ Transformed to N BigQuery events
- ✓ Validation shows either valid=True or duplicate error (both OK)
- ✓ Event has GDELT fields in metadata
- ✓ GKG enrichment present if available

**3. Verify response format preserved:**
Review function code confirms return value is still:
```python
{
    'events_created': int,
    'events_skipped': int,
    'events_fetched': int
}
```

**Note:** Actual deployment to GCP is NOT required for this verification. We're confirming the refactor is correct locally. Production deployment happens separately via `gcloud functions deploy`.

If all checks pass, the refactor is successful and behavior unchanged.
  </how-to-verify>
  <resume-signal>Type "approved" to continue, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Cloud Function imports GdeltAdapter successfully
- [ ] Function calls adapter.fetch/transform/validate methods
- [ ] Response format unchanged from original
- [ ] Local adapter integration test passes
- [ ] User verified behavior unchanged
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Cloud Function uses GdeltAdapter (no inline GDELT logic)
- Behavior identical to pre-refactor version
- Architecture migration complete
- Phase 22 complete: Plugin architecture ready for Phase 25 (new data sources)
</success_criteria>

<output>
After completion, create `.planning/phases/22-data-source-architecture/22-03-SUMMARY.md`
</output>
