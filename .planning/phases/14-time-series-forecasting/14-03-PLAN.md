---
phase: 14-time-series-forecasting
plan: 03
type: execute
---

<objective>
Implement Django forecasting API that wraps Vertex AI endpoint for on-demand entity risk trajectory predictions.

Purpose: Create backend services and API endpoints to generate forecasts from Vertex AI, cache results, and expose them to the frontend.
Output: REST API endpoint `/api/forecasting/entities/{entity_id}/forecast` returning 30-day risk trajectory with confidence intervals.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-time-series-forecasting/14-CONTEXT.md
@.planning/phases/14-time-series-forecasting/14-RESEARCH.md
@.planning/phases/14-time-series-forecasting/14-01-SUMMARY.md
@.planning/phases/14-time-series-forecasting/14-02-SUMMARY.md

**Tech stack available:**
- django-ninja for REST APIs (from Phase 1)
- Vertex AI endpoint deployed (from Plan 2)
- google-cloud-aiplatform SDK installed
- PostgreSQL with Entity and EntityMention models

**Established patterns:**
- Router pattern for API organization (from Phase 1)
- Typed API responses with Pydantic schemas
- 24-hour caching pattern for external API results (from Phase 3)

**From CONTEXT.md:**
- On-demand forecasting (not batch pre-computation)
- 30-day forecast horizon with confidence bands
- Dimensional breakdown (overall + sanctions/political/economic)
- "Forecast generated X hours ago" timestamp for freshness
- Disabled with explanation when insufficient data (<14 days history)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ForecastResult model for caching</name>
  <files>backend/forecasting/models.py, backend/forecasting/migrations/0001_initial.py</files>
  <action>
    Create Django model to cache forecast results:

    ```python
    from django.db import models
    from django.utils import timezone

    class ForecastResult(models.Model):
        """Cached forecast results from Vertex AI."""

        entity = models.ForeignKey(
            'entities.Entity',
            on_delete=models.CASCADE,
            related_name='forecasts'
        )
        forecast_data = models.JSONField(
            help_text="Forecast points with ds, yhat, yhat_lower, yhat_upper"
        )
        dimensional_forecasts = models.JSONField(
            null=True,
            blank=True,
            help_text="Dimensional breakdowns (sanctions, political, economic)"
        )
        horizon_days = models.IntegerField(default=30)
        generated_at = models.DateTimeField(default=timezone.now)
        model_version = models.CharField(
            max_length=255,
            blank=True,
            help_text="Vertex AI model resource name"
        )

        class Meta:
            db_table = 'forecasting_forecastresult'
            ordering = ['-generated_at']
            indexes = [
                models.Index(fields=['entity', '-generated_at']),
            ]

        def is_stale(self, hours=24):
            """Check if forecast is older than threshold."""
            return timezone.now() - self.generated_at > timezone.timedelta(hours=hours)

        def __str__(self):
            return f"Forecast for {self.entity} ({self.generated_at})"
    ```

    Create migration: python backend/manage.py makemigrations forecasting
    Apply migration: python backend/manage.py migrate

    Model stores JSON forecast data (time series points), dimensional breakdowns, and metadata. Index on (entity, generated_at) for efficient cache lookups. is_stale() method implements 24-hour TTL check.
  </action>
  <verify>
    1. Run: python backend/manage.py makemigrations forecasting
    2. Check: Migration file created in backend/forecasting/migrations/
    3. Run: python backend/manage.py migrate
    4. Verify: python backend/manage.py shell -c "from forecasting.models import ForecastResult; print('OK')"
  </verify>
  <done>ForecastResult model created with fields for forecast data, dimensions, timestamps, and model version. Migration applied successfully. Model includes is_stale() helper for TTL checks.</done>
</task>

<task type="auto">
  <name>Task 2: Implement VertexAIForecaster service</name>
  <files>backend/forecasting/services.py</files>
  <action>
    Create service class wrapping Vertex AI endpoint:

    ```python
    from google.cloud import aiplatform
    from django.conf import settings
    import pandas as pd
    from typing import Dict, List
    import logging

    logger = logging.getLogger(__name__)

    class VertexAIForecaster:
        """Service for generating forecasts via Vertex AI endpoint."""

        def __init__(self):
            aiplatform.init(
                project=settings.VERTEX_AI_PROJECT_ID,
                location=settings.VERTEX_AI_LOCATION
            )
            self.endpoint = aiplatform.Endpoint(settings.VERTEX_AI_ENDPOINT_ID)

        def forecast(self, entity_id: int, horizon_days: int = 30) -> Dict:
            """
            Generate forecast for entity.

            Args:
                entity_id: Entity ID to forecast
                horizon_days: Forecast horizon (default 30)

            Returns:
                Dict with 'forecast' (list of points) and 'metadata'

            Raises:
                InsufficientDataError: Less than 14 days of history
                VertexAIError: Prediction request failed
            """
            from entities.models import EntityMention

            # Check data sufficiency (14 days minimum per RESEARCH.md)
            history_count = EntityMention.objects.filter(
                entity_id=entity_id
            ).values('mentioned_at__date').distinct().count()

            if history_count < 14:
                raise InsufficientDataError(
                    f"Need 14 days of history, found {history_count}"
                )

            # Prepare prediction instance
            instances = [{
                'entity_id': str(entity_id),
            }]

            try:
                # Get predictions from Vertex AI
                prediction = self.endpoint.predict(instances=instances)

                # Parse response into forecast format
                forecast_points = []
                for pred in prediction.predictions[0].get('value', []):
                    forecast_points.append({
                        'ds': pred.get('time'),  # Timestamp
                        'yhat': pred.get('value'),  # Predicted risk score
                        'yhat_lower': pred.get('prediction_interval_lower_bound'),
                        'yhat_upper': pred.get('prediction_interval_upper_bound'),
                    })

                return {
                    'forecast': forecast_points[:horizon_days],
                    'metadata': {
                        'entity_id': entity_id,
                        'horizon_days': horizon_days,
                        'model_version': self.endpoint.resource_name,
                    }
                }

            except Exception as e:
                logger.error(f"Vertex AI prediction failed for entity {entity_id}: {e}")
                raise VertexAIError(f"Prediction failed: {str(e)}")


    class InsufficientDataError(Exception):
        """Raised when entity lacks minimum history for forecasting."""
        pass


    class VertexAIError(Exception):
        """Raised when Vertex AI prediction request fails."""
        pass
    ```

    Service wraps endpoint.predict() calls. Checks for 14-day minimum history (per RESEARCH.md pitfall #1). Returns forecast in format matching Prophet convention (ds, yhat, yhat_lower, yhat_upper) for frontend compatibility. Raises specific exceptions for insufficient data vs API failures.
  </action>
  <verify>
    1. Check: python -c "from forecasting.services import VertexAIForecaster; print('OK')" succeeds
    2. Validate: Class has forecast() method with entity_id and horizon_days parameters
    3. Confirm: InsufficientDataError and VertexAIError exceptions defined
  </verify>
  <done>VertexAIForecaster service implemented with endpoint wrapper. forecast() method checks data sufficiency, calls Vertex AI, and returns structured forecast data. Custom exceptions for insufficient data and API failures.</done>
</task>

<task type="auto">
  <name>Task 3: Create forecast API endpoint with caching</name>
  <files>backend/forecasting/api.py, backend/forecasting/schemas.py, backend/venezuelawatch/urls.py</files>
  <action>
    1. Create Pydantic schemas in `backend/forecasting/schemas.py`:

    ```python
    from pydantic import BaseModel
    from typing import List, Optional
    from datetime import datetime

    class ForecastPoint(BaseModel):
        ds: datetime
        yhat: float
        yhat_lower: float
        yhat_upper: float

    class ForecastResponse(BaseModel):
        status: str  # "ready", "generating", "insufficient_data"
        forecast: Optional[List[ForecastPoint]] = None
        generated_at: Optional[datetime] = None
        horizon_days: int
        message: Optional[str] = None  # For "insufficient_data" explanation
    ```

    2. Create API router in `backend/forecasting/api.py`:

    ```python
    from ninja import Router
    from django.shortcuts import get_object_or_404
    from django.utils import timezone
    from datetime import timedelta
    from entities.models import Entity
    from .models import ForecastResult
    from .services import VertexAIForecaster, InsufficientDataError, VertexAIError
    from .schemas import ForecastResponse
    import json

    router = Router()

    @router.post('/entities/{entity_id}/forecast', response=ForecastResponse)
    def get_entity_forecast(request, entity_id: int, horizon_days: int = 30):
        """
        Get forecast for entity risk trajectory.

        Returns cached forecast if <24 hours old, otherwise generates new forecast.
        """
        entity = get_object_or_404(Entity, id=entity_id)

        # Check for recent cached forecast
        cached = ForecastResult.objects.filter(
            entity=entity,
            horizon_days=horizon_days,
            generated_at__gte=timezone.now() - timedelta(hours=24)
        ).first()

        if cached and not cached.is_stale(hours=24):
            return {
                'status': 'ready',
                'forecast': json.loads(cached.forecast_data),
                'generated_at': cached.generated_at,
                'horizon_days': horizon_days,
            }

        # Generate new forecast
        try:
            forecaster = VertexAIForecaster()
            result = forecaster.forecast(entity_id, horizon_days)

            # Cache result
            ForecastResult.objects.create(
                entity=entity,
                forecast_data=json.dumps(result['forecast']),
                horizon_days=horizon_days,
                model_version=result['metadata']['model_version'],
            )

            return {
                'status': 'ready',
                'forecast': result['forecast'],
                'generated_at': timezone.now(),
                'horizon_days': horizon_days,
            }

        except InsufficientDataError as e:
            return {
                'status': 'insufficient_data',
                'horizon_days': horizon_days,
                'message': str(e),
            }

        except VertexAIError as e:
            return {
                'status': 'error',
                'horizon_days': horizon_days,
                'message': f"Forecast generation failed: {str(e)}",
            }
    ```

    3. Register router in `backend/venezuelawatch/urls.py`:

    ```python
    from forecasting.api import router as forecasting_router

    api.add_router('/forecasting/', forecasting_router)
    ```

    Endpoint checks cache first (24-hour TTL per CONTEXT.md). If stale/missing, calls VertexAIForecaster service. Returns "insufficient_data" status with explanation when entity has <14 days history (matches CONTEXT.md disabled-with-explanation requirement). Caches successful forecasts for 24 hours.
  </action>
  <verify>
    1. Check: python backend/manage.py runserver starts without errors
    2. Test: curl -X POST http://localhost:8000/api/forecasting/entities/1/forecast returns JSON
    3. Verify: Response has "status" field ("ready", "insufficient_data", or "error")
    4. Check: OpenAPI docs at /api/docs shows forecast endpoint
  </verify>
  <done>Forecast API endpoint created at /api/forecasting/entities/{entity_id}/forecast. Implements 24-hour caching, handles insufficient data gracefully, returns structured ForecastResponse. Router registered in main API. Endpoint documented in OpenAPI.</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] ForecastResult model created and migrated
- [ ] VertexAIForecaster service implemented with error handling
- [ ] API endpoint created and registered
- [ ] Cache lookup works (24-hour TTL)
- [ ] Insufficient data case returns appropriate message
- [ ] curl test returns valid JSON response
- [ ] OpenAPI docs include forecast endpoint
</verification>

<success_criteria>
- All tasks completed
- Django forecasting API operational
- 24-hour caching reduces Vertex AI costs
- Insufficient data handled gracefully per CONTEXT.md requirements
- Ready for frontend integration in next plan
</success_criteria>

<output>
After completion, create `.planning/phases/14-time-series-forecasting/14-03-SUMMARY.md`:

# Phase 14 Plan 3: Django Forecasting API Summary

**Forecast API operational: on-demand entity risk trajectory predictions with 24-hour caching**

## Accomplishments

- Created ForecastResult model for caching predictions (24-hour TTL)
- Implemented VertexAIForecaster service wrapping Vertex AI endpoint
- Built REST API endpoint with cache-first strategy
- Handled insufficient data case gracefully (<14 days history)
- Integrated with django-ninja router pattern and OpenAPI docs

## Files Created/Modified

- `backend/forecasting/models.py` - ForecastResult cache model
- `backend/forecasting/migrations/0001_initial.py` - Database migration
- `backend/forecasting/services.py` - VertexAIForecaster service, custom exceptions
- `backend/forecasting/api.py` - REST API endpoint with caching
- `backend/forecasting/schemas.py` - Pydantic response schemas
- `backend/venezuelawatch/urls.py` - Registered forecasting router

## Decisions Made

- 24-hour cache TTL balances freshness and cost (per CONTEXT.md)
- Cache lookup before Vertex AI call (minimize prediction costs at $0.20/1K)
- InsufficientDataError for <14 days (matches RESEARCH.md minimum)
- Structured response with status field ("ready", "insufficient_data", "error")
- Prophet-compatible format (ds, yhat, yhat_lower, yhat_upper) for frontend reuse

## Issues Encountered

[Document any Vertex AI API issues, response parsing challenges, or "None"]

## Next Step

Ready for 14-04-PLAN.md: Frontend Forecast Visualization
</output>
