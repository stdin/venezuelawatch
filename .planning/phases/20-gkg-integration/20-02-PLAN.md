---
phase: 20-gkg-integration
plan: 02
type: execute
---

<objective>
Parse GKG delimited string fields and enhance intelligence pipeline with GKG themes, entities, and tone data.

Purpose: Transform raw GKG data into structured intelligence signals for risk scoring and entity extraction.
Output: Parsed GKG fields in metadata, entity extraction enhanced with GKG Persons/Organizations data.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/20-gkg-integration/DISCOVERY.md
@.planning/phases/20-gkg-integration/20-01-SUMMARY.md
@backend/data_pipeline/tasks/gdelt_sync_task.py
@backend/api/services/gdelt_field_reference.py

**Tech stack available:**
- Python string parsing (split, regex)
- Existing field reference utility pattern (gdelt_field_reference.py)
- JSON metadata storage in BigQuery

**Established patterns:**
- Field reference utilities for code interpretation (Phase 19)
- Category-based metadata organization (Phase 19)
- Snake_case metadata keys
- Venezuela-relevant subset focus (not exhaustive)

**Constraining decisions:**
- Phase 19: Category-based metadata organization for schema extensions
- Phase 19: Snake_case metadata keys for consistency
- Phase 20 Discovery: V2 fields preferred (V2Themes, V2Persons, V2Organizations, V2Locations, V2Tone)
- Phase 20 Discovery: Python-side parsing (not BigQuery) for maintainability

**GKG Field Formats (from DISCOVERY.md):**
- V2Themes: Semicolon-separated (e.g., "ECON_CURRENCY;CIVILIAN;PROTEST")
- V2Persons: Complex with counts (e.g., "Person Name,Offset,Length;...")
- V2Organizations: Same format as Persons
- V2Locations: Includes lat/long (e.g., "2#Venezuela#VE#VE##-8#-66#VE#USVE#Venezuela;...")
- V2Tone: Comma-separated metrics (tone, positive, negative, polarity, activity, self/group refs, word count)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GKG Field Parsers</name>
  <files>backend/api/services/gdelt_gkg_parsers.py</files>
  <action>
Create new module gdelt_gkg_parsers.py with parser functions:

1. parse_v2_themes(themes_str: Optional[str]) -> List[str]: Split on semicolon, return list of theme codes. Empty string returns empty list, None returns empty list.

2. parse_v2_persons(persons_str: Optional[str]) -> List[str]: Extract person names only (ignore offsets). Format is "Name,Offset,Length;Name,Offset,Length;...". Split on semicolon, then split each on comma, take first element. Return deduplicated list of names.

3. parse_v2_organizations(orgs_str: Optional[str]) -> List[str]: Same format/logic as parse_v2_persons.

4. parse_v2_locations(locations_str: Optional[str]) -> List[Dict[str, Any]]: Format is "Type#Name#CountryCode#...#Lat#Long#...;...". Split on semicolon, for each location split on #, extract {name, country_code, lat, long}. Return list of dicts with these keys. Skip entries missing lat/long.

5. parse_v2_tone(tone_str: Optional[str]) -> Dict[str, float]: Format is "tone,positive%,negative%,polarity,activity,self_refs,group_refs,word_count". Split on comma, return dict with keys: tone, positive_pct, negative_pct, polarity, activity_density, self_refs, group_refs, word_count. Handle missing values (return None for that key).

All parsers handle None/empty string gracefully (return empty list/dict), handle malformed data (log warning, return partial data or empty).

Add Venezuela-relevant theme reference dict VENEZUELA_RELEVANT_THEMES = {'ECON_CURRENCY', 'CIVILIAN', 'PROTEST', 'LEADER', 'GOVERNMENT', 'SANCTIONS', ...} (10-15 common themes, reference GKG documentation).
  </action>
  <verify>
python -c "from api.services.gdelt_gkg_parsers import parse_v2_themes, parse_v2_persons; print(parse_v2_themes('A;B;C')); print(parse_v2_persons('John Doe,0,8;Jane Smith,10,10'))" outputs ['A', 'B', 'C'] and ['John Doe', 'Jane Smith']
  </verify>
  <done>gdelt_gkg_parsers.py exists with all 5 parser functions, handles None/empty gracefully, returns correct data structures, includes Venezuela-relevant theme reference dict</done>
</task>

<task type="auto">
  <name>Task 2: Integrate GKG Parsing in Sync Task</name>
  <files>backend/data_pipeline/tasks/gdelt_sync_task.py</files>
  <action>
In sync_gdelt_events, after fetching GKG raw data (from Plan 01), before building metadata dict:

1. Import all parser functions from gdelt_gkg_parsers
2. If event has 'gkg_raw' key with data:
   - Parse V2Themes: themes_list = parse_v2_themes(gkg_raw.get('V2Themes'))
   - Parse V2Persons: persons_list = parse_v2_persons(gkg_raw.get('V2Persons'))
   - Parse V2Organizations: orgs_list = parse_v2_organizations(gkg_raw.get('V2Organizations'))
   - Parse V2Locations: locations_list = parse_v2_locations(gkg_raw.get('V2Locations'))
   - Parse V2Tone: tone_dict = parse_v2_tone(gkg_raw.get('V2Tone'))

3. When building metadata dict for BigQuery, replace 'gkg_data' (raw) with structured 'gkg' dict:
   ```python
   'gkg': {
       'record_id': gkg_raw['GKGRECORDID'],
       'source': gkg_raw.get('SourceCommonName'),
       'themes': themes_list,
       'persons': persons_list,
       'organizations': orgs_list,
       'locations': locations_list,
       'tone': tone_dict,
       'quotations': gkg_raw.get('Quotations', ''),  # keep raw for now
       'gcam': gkg_raw.get('GCAM', '')  # keep raw for now, complex format
   }
   ```

Log count of parsed themes, persons, orgs for observability. Handle parsing errors gracefully (log warning, store partial data).
  </action>
  <verify>
Run sync_gdelt_events(lookback_minutes=60), check BigQuery events table shows metadata.gkg with parsed lists/dicts (not raw strings), check logs show "Parsed X themes, Y persons, Z orgs" for events with GKG
  </verify>
  <done>Sync task parses GKG fields using parser functions, stores structured data in metadata.gkg, logs parsing statistics, handles errors gracefully</done>
</task>

<task type="auto">
  <name>Task 3: Enhance Entity Extraction with GKG Data</name>
  <files>backend/cloud_functions/intelligence_processor.py</files>
  <action>
In process_intelligence Cloud Function, when creating/updating entity mentions:

1. Check if event dict has metadata.gkg.persons or metadata.gkg.organizations
2. If GKG persons exist, before or after LLM entity extraction:
   - For each person in metadata.gkg.persons: create/get Entity with type='Person' and name from GKG
   - Create EntityMention linking Entity to event
   - Deduplicate against LLM-extracted entities using existing fuzzy matching (Jaro-Winkler 0.85)
3. Same for GKG organizations (type='Organization')

This supplements LLM entity extraction with structured GKG entities. GKG entities are high-confidence (extracted by GDELT from article structure), LLM entities capture context/relationships.

Tag GKG-sourced entities with source='gkg' in EntityMention for attribution. Log count of GKG-sourced vs LLM-sourced entities for metrics.

Do NOT remove or replace LLM entity extraction - this is additive enrichment.
  </action>
  <verify>
Run manual intelligence processing on an event with GKG persons/orgs, check EntityMention records show source='gkg' for some entities, check no duplicate entities created (fuzzy matching working)
  </verify>
  <done>Intelligence processor creates EntityMention records from GKG persons/organizations, deduplicates with LLM entities, tags source, logs entity source metrics</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] python -c "from api.services.gdelt_gkg_parsers import parse_v2_themes" succeeds
- [ ] All 5 parser functions exist and handle None/empty strings
- [ ] Sync task uses parsers and stores structured GKG data in metadata.gkg
- [ ] BigQuery events table shows parsed GKG fields (lists/dicts, not raw strings)
- [ ] Intelligence processor creates entities from GKG data
- [ ] EntityMention records show source='gkg' attribution
- [ ] No duplicate entities created (deduplication working)
</verification>

<success_criteria>

- GKG parser module created with 5 field parsers
- Parsers handle all GKG V2 field formats correctly
- Sync task integrates parsing, stores structured GKG in metadata.gkg
- Entity extraction enhanced with GKG Persons/Organizations data
- Deduplication prevents duplicate entities from GKG + LLM sources
- Source attribution added (source='gkg' vs source='llm')
- Observability: logs show parsing and entity source metrics
- Phase 20 complete: GKG integration operational
</success_criteria>

<output>
After completion, create `.planning/phases/20-gkg-integration/20-02-SUMMARY.md`:

# Phase 20 Plan 02: GKG Parsing & Intelligence Enhancement Summary

**[Substantive one-liner describing GKG parsing and intelligence integration]**

## Accomplishments

- Created GKG field parsers for V2Themes, Persons, Organizations, Locations, Tone
- Integrated parsing into sync pipeline with structured metadata storage
- Enhanced entity extraction with GKG Persons/Organizations data
- Implemented entity deduplication and source attribution

## Files Created/Modified

- `backend/api/services/gdelt_gkg_parsers.py` - GKG field parsers
- `backend/data_pipeline/tasks/gdelt_sync_task.py` - Integrated parsing
- `backend/cloud_functions/intelligence_processor.py` - GKG entity extraction

## Decisions Made

- Parser functions separate from service for testability
- GKG entities supplement (not replace) LLM extraction
- Source attribution via source='gkg' field in EntityMention
- Quotations and GCAM kept raw (complex parsing deferred)

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Phase Readiness

**Phase 20: GKG Integration - COMPLETE**

Ready for Phase 21: Mentions Tracking
- GKG data enrichment operational (themes, entities, tone)
- Entity extraction enhanced with structured GDELT data
- Foundation for theme-based risk scoring in Phase 23
- Quotations available for future sentiment analysis
</output>
