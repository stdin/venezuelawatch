---
phase: 07-ai-chat-interface
plan: 01
type: execute
---

<objective>
Implement Django backend chat API with Anthropic Claude streaming and tool calling for data access.

Purpose: Provide the backend foundation for AI chat - streaming responses, tool execution for querying events/entities/risk data, and conversation context management.
Output: Working /api/chat endpoint that streams Claude responses and executes tools to fetch VenezuelaWatch data.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-phase.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-ai-chat-interface/07-CONTEXT.md
@backend/venezuelawatch/api.py
@backend/data_pipeline/api.py
@backend/requirements.txt

**Tech stack available:**
- Django 5.2 with django-ninja for REST APIs
- anthropic>=0.75.0 already installed
- PostgreSQL with TimescaleDB for event/entity data
- Existing API endpoints: /api/risk, /api/entities, /api/events

**Established patterns:**
- django-ninja router pattern for API organization
- Router registration in backend/venezuelawatch/api.py
- JSON responses with TypeScript-compatible schemas

**From CONTEXT.md:**
- Priority: Natural conversation quality over feature breadth
- Query types: real-time intelligence, entity research, analytical deep-dives, report generation
- Claude API (Anthropic) preferred for LLM
- Tools must access existing VenezuelaWatch data (events, entities, risk scores)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Django chat API router with streaming support</name>
  <files>backend/chat/api.py, backend/chat/__init__.py, backend/venezuelawatch/api.py</files>
  <action>
Create new backend/chat/ Django app with api.py implementing POST /chat endpoint.

Endpoint accepts:
- messages: list of {role: "user"|"assistant", content: string}
- stream: boolean (default true)

Use anthropic SDK for streaming with claude-3-5-sonnet-20241022 model. Return Server-Sent Events (SSE) stream for frontend consumption. Use AsyncStreamingHttpResponse from Django.

Register chat_router in backend/venezuelawatch/api.py with prefix "/chat".

DO NOT use Vercel AI SDK patterns (Next.js specific). This is Django backend - use plain anthropic SDK with SSE streaming.

Key implementation:
- Import anthropic library
- Create Anthropic client with API key from environment (ANTHROPIC_API_KEY)
- Stream message deltas using client.messages.stream()
- Format SSE: "data: {json}\n\n" for each chunk
- Handle errors with proper HTTP status codes
  </action>
  <verify>curl -X POST http://localhost:8000/api/chat -H "Content-Type: application/json" -d '{"messages":[{"role":"user","content":"Hello"}]}' streams SSE responses</verify>
  <done>Chat endpoint streams Claude responses in SSE format, handles message history, returns proper error codes</done>
</task>

<task type="auto">
  <name>Task 2: Implement tool calling for VenezuelaWatch data access</name>
  <files>backend/chat/tools.py, backend/chat/api.py</files>
  <action>
Create backend/chat/tools.py defining 4 Anthropic tool functions:

1. **search_events** - Query events by filters
   - Parameters: date_from, date_to, risk_threshold, source, limit
   - Returns: List of events with id, title, date, source, risk_score, severity, summary
   - Implementation: Query Event model, apply filters, serialize

2. **get_entity_profile** - Get detailed entity information
   - Parameters: entity_name (required)
   - Returns: Entity with type, mention_count, avg_risk_score, is_sanctioned, recent_mentions
   - Implementation: EntityService.get_or_create_entity + aggregation queries

3. **get_trending_entities** - List trending entities by metric
   - Parameters: metric ("mentions"|"risk"|"sanctions"), limit
   - Returns: List of entities with trend scores
   - Implementation: Call TrendingService methods

4. **analyze_risk_trends** - Get risk score trends over time
   - Parameters: days_back, event_types
   - Returns: Time-series data with dates and avg risk scores
   - Implementation: Query Event model with time bucketing

In api.py, pass tools to anthropic.messages.stream() and handle tool_use blocks by executing functions and returning results to Claude for final response generation.

Use Anthropic's tool calling format (not OpenAI format). Tool results get passed back to Claude in the conversation.
  </action>
  <verify>POST with message "What are the highest risk events today?" triggers search_events tool, returns event data in response</verify>
  <done>All 4 tools defined, integrated with streaming endpoint, tool execution works correctly, results incorporated into Claude responses</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] POST /api/chat endpoint exists and is registered
- [ ] Streaming works: SSE chunks arrive incrementally
- [ ] Tool calling works: Claude invokes search_events/get_entity_profile/etc when appropriate
- [ ] Tool results appear in final Claude responses
- [ ] Error handling returns proper HTTP status codes
- [ ] No authentication errors (ANTHROPIC_API_KEY loaded)
</verification>

<success_criteria>

- Chat API endpoint functional at /api/chat
- Anthropic Claude streaming implemented with SSE
- 4 VenezuelaWatch data tools defined and integrated
- Tool execution retrieves real data from database
- Conversation context maintained across messages
- No errors in Django logs during testing
</success_criteria>

<output>
After completion, create `.planning/phases/07-ai-chat-interface/07-01-SUMMARY.md`
</output>
