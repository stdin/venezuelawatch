---
phase: 21-mentions-tracking
plan: "02"
type: tdd
---

<objective>
Build spike detection service with z-score calculation and confidence classification using Test-Driven Development.

Purpose: TDD ensures accurate spike detection logic with edge case handling (zero stddev, missing baseline, threshold boundaries).
Output: Tested SpikeDetectionService with comprehensive test coverage for z-score math and confidence classification.
</objective>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-mentions-tracking/DISCOVERY.md
@.planning/phases/21-mentions-tracking/21-CONTEXT.md
@.planning/phases/21-mentions-tracking/21-01-SUMMARY.md

**From Discovery**:
- Z-score formula: `z = (x - μ) / σ`
- Confidence thresholds: z >= 2.0 (Medium), z >= 2.5 (High), z >= 3.0 (Critical)
- Edge cases: zero stddev → z = 0, missing baseline → skip

**Why TDD for spike detection**:
- Clear input/output behavior: mention stats → classified spikes
- Critical accuracy requirement (false positives degrade trust)
- Multiple edge cases to handle (zero stddev, missing data, threshold boundaries)
- Math-heavy logic benefits from test-first design
</context>

<feature>
  <name>Spike Detection with Z-Score Classification</name>
  <files>backend/api/services/spike_detection_service.py, backend/api/services/tests/test_spike_detection.py</files>
  <behavior>
**Input**: List of mention statistics from GDELTMentionsService
```python
[
  {
    'event_id': '1283174855',
    'mention_date': datetime.date(2026, 1, 10),
    'mention_count': 50,
    'rolling_avg': 10.0,
    'rolling_stddev': 8.0
  },
  ...
]
```

**Output**: List of detected spikes with z-scores and confidence levels
```python
[
  {
    'event_id': '1283174855',
    'spike_date': datetime.date(2026, 1, 10),
    'mention_count': 50,
    'baseline_avg': 10.0,
    'baseline_stddev': 8.0,
    'z_score': 5.0,  # (50 - 10) / 8
    'confidence_level': 'CRITICAL'  # z >= 3.0
  }
]
```

**Test Cases**:

1. **Normal spike detection**: mention_count=50, avg=10, stddev=8 → z=5.0, CRITICAL
2. **Medium confidence**: mention_count=25, avg=10, stddev=5 → z=3.0 (boundary), confidence=CRITICAL
3. **High confidence boundary**: mention_count=22.5, avg=10, stddev=5 → z=2.5 (exact), confidence=HIGH
4. **Medium confidence boundary**: mention_count=20, avg=10, stddev=5 → z=2.0 (exact), confidence=MEDIUM
5. **Below threshold**: mention_count=15, avg=10, stddev=5 → z=1.0, no spike (filtered out)
6. **Zero stddev edge case**: mention_count=10, avg=10, stddev=0 → z=0, no spike
7. **Missing baseline (None values)**: rolling_avg=None → skip, no spike
8. **Negative z-score**: mention_count=5, avg=10, stddev=3 → z=-1.67, no spike (negative = decline, not spike)

**Implementation approach**:
- Function: `detect_spikes(mention_stats: List[dict]) -> List[dict]`
- Iterate through mention_stats
- Skip if rolling_avg or rolling_stddev is None
- Handle stddev=0 → z=0
- Calculate z-score: (mention_count - rolling_avg) / rolling_stddev
- Classify confidence: z >= 3.0 → CRITICAL, z >= 2.5 → HIGH, z >= 2.0 → MEDIUM
- Filter: only return spikes with z >= 2.0
- Return list of spike dicts
  </behavior>
  <implementation>
After tests pass, create SpikeDetectionService class in backend/api/services/spike_detection_service.py:

```python
class SpikeDetectionService:
    """Detects mention spikes using z-score statistical analysis."""

    @staticmethod
    def detect_spikes(mention_stats: List[dict]) -> List[dict]:
        """
        Calculate z-scores and classify spikes from mention statistics.

        Args:
            mention_stats: List of dicts with event_id, mention_date, mention_count,
                          rolling_avg, rolling_stddev from GDELTMentionsService

        Returns:
            List of spike dicts with z_score and confidence_level for spikes >= 2.0
        """
        spikes = []

        for stat in mention_stats:
            # Skip if insufficient baseline data
            if stat['rolling_avg'] is None or stat['rolling_stddev'] is None:
                continue

            # Handle zero stddev edge case (flat baseline)
            if stat['rolling_stddev'] == 0:
                z_score = 0.0
            else:
                z_score = (
                    stat['mention_count'] - stat['rolling_avg']
                ) / stat['rolling_stddev']

            # Only detect positive spikes (z >= 2.0)
            if z_score < 2.0:
                continue

            # Classify confidence level
            if z_score >= 3.0:
                confidence = 'CRITICAL'
            elif z_score >= 2.5:
                confidence = 'HIGH'
            else:  # z >= 2.0
                confidence = 'MEDIUM'

            spikes.append({
                'event_id': stat['event_id'],
                'spike_date': stat['mention_date'],
                'mention_count': stat['mention_count'],
                'baseline_avg': stat['rolling_avg'],
                'baseline_stddev': stat['rolling_stddev'],
                'z_score': z_score,
                'confidence_level': confidence
            })

        return spikes

# Singleton instance
spike_detection_service = SpikeDetectionService()
```

Add singleton at bottom of file for consistent service pattern.
  </implementation>
</feature>

<verification>
pytest backend/api/services/tests/test_spike_detection.py -v passes all tests covering normal cases, edge cases, and threshold boundaries
</verification>

<success_criteria>
- Failing test written and committed (RED phase)
- Implementation passes all tests (GREEN phase)
- Refactor complete if needed (REFACTOR phase)
- All 2-3 commits present (test, feat, optional refactor)
- Coverage includes edge cases: zero stddev, missing baseline, negative z-scores
</success_criteria>

<output>
After completion, create `.planning/phases/21-mentions-tracking/21-02-SUMMARY.md`:

# Phase 21 Plan 02: Spike Detection Logic (TDD) Summary

**Z-score spike detection with statistical confidence classification, built test-first**

## Accomplishments

- **RED**: Wrote comprehensive test suite covering 8 test cases (normal spikes, edge cases, threshold boundaries)
- **GREEN**: Implemented SpikeDetectionService.detect_spikes with z-score calculation and confidence classification
- **REFACTOR**: [If applicable - code cleanup while maintaining test pass]

## Files Created/Modified

- `backend/api/services/tests/test_spike_detection.py` - Comprehensive test suite
- `backend/api/services/spike_detection_service.py` - Spike detection service with z-score logic

## Decisions Made

- Return only positive spikes (z >= 2.0) - negative z-scores are declines, not spikes
- Zero stddev returns z=0, not error - new events with flat baselines handled gracefully
- Skip records with None baseline - insufficient data for detection
- Thresholds at exact boundaries (2.0, 2.5, 3.0) use >= comparison for inclusive classification

## Commits

1. `test(21-02): add failing test for spike detection` - RED phase
2. `feat(21-02): implement spike detection with z-scores` - GREEN phase
3. `refactor(21-02): [description]` - REFACTOR phase (if applicable)

## Next Phase Readiness

Ready for Plan 21-03 (Cloud Function for daily mention tracking)
</output>
