# Phase 23-01 Plan: GDELT Quantitative Scorer Implementation

**Phase:** 23 - Intelligence Pipeline Rebuild
**Task:** 23-01 - GDELT Quantitative Scorer
**Date:** 2026-01-10

## Objective

Build the GDELT quantitative scoring module that computes a 0-100 risk score from GDELT's four signals: Goldstein scale, tone, GKG themes, and theme intensity. This scorer will provide the quantitative component of the hybrid scoring system.

## Context

From 23-CONTEXT.md and 23-RESEARCH.md:
- **GDELT provides base quantitative score (0-100)** using all 4 signals weighted
- **LLM will see this score** and combine it with qualitative analysis
- **Configurable weights** to support experimentation and tuning
- **Standard library stack**: scikit-learn for MinMaxScaler, numpy for weighted average
- **Formula approach**: User open to best practices (no specific formula mandated)

## Dependencies Met

✅ **Phase 22 Complete**: GdeltAdapter stores all 61 GDELT fields in metadata
✅ **GDELT Data Available**: Events have `goldstein_scale`, `avg_tone`, and `metadata.gkg.themes`
✅ **BigQuery Pipeline**: Events stored with complete metadata for scoring

## Scope

### In Scope
1. Create `GdeltQuantitativeScorer` class with normalization and weighted scoring
2. Implement scoring for all 4 GDELT signals:
   - Goldstein scale (-10 to +10, inverted: negative = higher risk)
   - Tone (-100 to +100, inverted: negative = higher risk)
   - GKG themes (CRISIS/PROTEST/CONFLICT presence)
   - Theme intensity (count/frequency of high-risk themes)
3. Configurable signal weights (via settings or class parameters)
4. Handle edge cases (missing GKG data, out-of-range values)
5. Unit tests with real GDELT metadata examples

### Out of Scope
- LLM integration (Task 23-02)
- Intelligence pipeline refactoring (Task 23-02)
- Frontend changes
- Historical score recalculation (admin feature for later)

## Technical Design

### File Structure

```
backend/data_pipeline/services/
├── gdelt_quantitative_scorer.py  # NEW: Scorer class
└── tests/
    └── test_gdelt_quantitative_scorer.py  # NEW: Unit tests
```

### Core Implementation

**Class: `GdeltQuantitativeScorer`**

```python
"""
GDELT quantitative risk scoring using tone, Goldstein scale, themes, and theme intensity.

Computes 0-100 risk score from GDELT signals with configurable weights.
"""
from typing import Dict, Any, List, Optional
import numpy as np
from sklearn.preprocessing import MinMaxScaler


class GdeltQuantitativeScorer:
    """
    Compute quantitative risk score (0-100) from GDELT event signals.

    Uses 4 weighted signals:
    1. Goldstein scale: Event cooperation/conflict score (-10 to +10)
    2. Tone: GDELT sentiment analysis (-100 to +100)
    3. GKG themes: Presence of CRISIS, PROTEST, CONFLICT themes
    4. Theme intensity: Count/frequency of high-risk themes

    Attributes:
        weights (dict): Configurable signal weights (must sum to 1.0)
        high_risk_themes (set): GKG themes indicating elevated risk
    """

    # Default weights (can be overridden)
    DEFAULT_WEIGHTS = {
        'goldstein': 0.35,   # Primary conflict indicator
        'tone': 0.25,        # Sentiment signal
        'themes': 0.25,      # Categorical risk themes
        'intensity': 0.15    # Theme frequency
    }

    # High-risk GKG themes
    HIGH_RISK_THEMES = {
        'CRISIS', 'PROTEST', 'CONFLICT', 'VIOLENCE', 'WAR',
        'TERRORISM', 'RIOT', 'UNREST', 'SANCTIONS', 'EMBARGO'
    }

    def __init__(self, weights: Optional[Dict[str, float]] = None):
        """
        Initialize scorer with configurable weights.

        Args:
            weights: Optional dict with keys: goldstein, tone, themes, intensity
                    Must sum to 1.0. Defaults to DEFAULT_WEIGHTS.

        Raises:
            ValueError: If weights don't sum to 1.0
        """
        self.weights = weights or self.DEFAULT_WEIGHTS.copy()

        # Validate weights
        weight_sum = sum(self.weights.values())
        if not (0.99 <= weight_sum <= 1.01):  # Allow floating point tolerance
            raise ValueError(f"Weights must sum to 1.0, got {weight_sum}")

        # Initialize scalers (fit on codebook ranges, not data)
        self.goldstein_scaler = MinMaxScaler(feature_range=(0, 100))
        self.goldstein_scaler.fit([[-10], [10]])

        self.tone_scaler = MinMaxScaler(feature_range=(0, 100))
        self.tone_scaler.fit([[-100], [100]])

    def score_event(self, event_metadata: dict) -> float:
        """
        Compute quantitative risk score from GDELT event metadata.

        Args:
            event_metadata: Event metadata dict with GDELT fields
                Expected fields: goldstein_scale, avg_tone, gkg (optional)

        Returns:
            Risk score (0-100), where 100 = highest risk
        """
        scores = []

        # 1. Goldstein scale (invert: negative values = higher risk)
        goldstein = event_metadata.get('goldstein_scale', 0)
        goldstein_inverted = -goldstein  # -10 becomes +10 (high risk)
        goldstein_score = self.goldstein_scaler.transform([[goldstein_inverted]])[0][0]
        scores.append((goldstein_score, self.weights['goldstein']))

        # 2. Tone (invert: negative sentiment = higher risk)
        tone = event_metadata.get('avg_tone', 0)
        tone_inverted = -tone  # -100 becomes +100 (high risk)
        tone_score = self.tone_scaler.transform([[tone_inverted]])[0][0]
        scores.append((tone_score, self.weights['tone']))

        # 3. GKG themes (categorical presence)
        themes_score = self._score_themes(event_metadata.get('gkg', {}))
        scores.append((themes_score, self.weights['themes']))

        # 4. Theme intensity (count/frequency)
        intensity_score = self._score_theme_intensity(event_metadata.get('gkg', {}))
        scores.append((intensity_score, self.weights['intensity']))

        # Weighted average
        values = [score for score, weight in scores]
        weights = [weight for score, weight in scores]
        final_score = float(np.average(values, weights=weights))

        # Clamp to 0-100 range
        return max(0.0, min(100.0, final_score))

    def _score_themes(self, gkg_data: dict) -> float:
        """
        Score based on presence of high-risk GKG themes.

        Args:
            gkg_data: Parsed GKG data with 'themes' key

        Returns:
            Score (0-100) based on theme presence
        """
        themes = gkg_data.get('themes', [])
        if not themes:
            return 50.0  # Neutral score when GKG data missing

        # Extract theme names (themes are dicts with 'name' key)
        theme_names = set()
        for theme in themes:
            if isinstance(theme, dict) and 'name' in theme:
                theme_names.add(theme['name'].upper())
            elif isinstance(theme, str):
                theme_names.add(theme.upper())

        # Count high-risk themes
        risk_themes_found = theme_names & self.HIGH_RISK_THEMES

        if not risk_themes_found:
            return 20.0  # Low risk if no concerning themes

        # Scale: 1 theme = 60, 2 themes = 80, 3+ themes = 100
        risk_count = len(risk_themes_found)
        if risk_count >= 3:
            return 100.0
        elif risk_count == 2:
            return 80.0
        else:
            return 60.0

    def _score_theme_intensity(self, gkg_data: dict) -> float:
        """
        Score based on frequency/intensity of high-risk themes.

        Args:
            gkg_data: Parsed GKG data with 'themes' key

        Returns:
            Score (0-100) based on theme intensity
        """
        themes = gkg_data.get('themes', [])
        if not themes:
            return 50.0  # Neutral score when GKG data missing

        # Count total high-risk theme mentions
        risk_mentions = 0
        for theme in themes:
            theme_name = ''
            if isinstance(theme, dict):
                theme_name = theme.get('name', '').upper()
            elif isinstance(theme, str):
                theme_name = theme.upper()

            if theme_name in self.HIGH_RISK_THEMES:
                risk_mentions += 1

        # Scale intensity: 0 mentions = 20, 1-2 = 50, 3-5 = 75, 6+ = 100
        if risk_mentions == 0:
            return 20.0
        elif risk_mentions <= 2:
            return 50.0
        elif risk_mentions <= 5:
            return 75.0
        else:
            return 100.0
```

### Testing Strategy

**Unit Tests** (`test_gdelt_quantitative_scorer.py`):

1. **Test initialization and weight validation**
   - Default weights sum to 1.0
   - Custom weights validated
   - Invalid weights raise ValueError

2. **Test Goldstein scale scoring**
   - Negative values (conflict) → high score
   - Positive values (cooperation) → low score
   - Edge cases: -10, +10, 0

3. **Test tone scoring**
   - Negative tone → high score
   - Positive tone → low score
   - Edge cases: -100, +100, 0

4. **Test GKG theme scoring**
   - CRISIS/PROTEST/CONFLICT themes → elevated score
   - No high-risk themes → low score
   - Missing GKG data → neutral score (50)

5. **Test theme intensity scoring**
   - Multiple mentions of risk themes → higher score
   - Few mentions → moderate score
   - No mentions → low score

6. **Test end-to-end scoring with realistic GDELT metadata**
   - High-risk event (negative Goldstein, negative tone, CRISIS themes)
   - Low-risk event (positive Goldstein, positive tone, no risk themes)
   - Mixed signals event

7. **Test configurable weights**
   - Override default weights
   - Verify weighted average calculation

### Integration Points

**With Phase 22 (GdeltAdapter):**
- Reads GDELT metadata from `event.metadata` (all 61 fields available)
- Uses `goldstein_scale`, `avg_tone`, and `metadata.gkg.themes`

**With Task 23-02 (Intelligence Pipeline):**
- Scorer will be called during LLM analysis phase
- Score passed to LLM in prompt for hybrid assessment

## Implementation Tasks

### Task 1: Create GdeltQuantitativeScorer class
**File:** `backend/data_pipeline/services/gdelt_quantitative_scorer.py`

**Steps:**
1. Create class with initialization and weight validation
2. Implement Goldstein scale scoring (inverted normalization)
3. Implement tone scoring (inverted normalization)
4. Implement theme presence scoring (categorical)
5. Implement theme intensity scoring (frequency-based)
6. Implement `score_event()` with weighted average aggregation

**Acceptance Criteria:**
- Class initializes with default or custom weights
- All 4 scoring methods implemented
- Weights validated (must sum to 1.0)
- Score clamped to 0-100 range
- Handles missing GKG data gracefully (neutral score)

### Task 2: Write comprehensive unit tests
**File:** `backend/data_pipeline/services/tests/test_gdelt_quantitative_scorer.py`

**Steps:**
1. Test weight validation (default, custom, invalid)
2. Test Goldstein scale scoring (negative, positive, zero, edge cases)
3. Test tone scoring (negative, positive, zero, edge cases)
4. Test theme scoring (CRISIS, PROTEST, CONFLICT, no themes, missing GKG)
5. Test intensity scoring (multiple mentions, few, none)
6. Test end-to-end with realistic metadata from GDELT events
7. Test configurable weights affect final score

**Acceptance Criteria:**
- All tests pass
- Coverage ≥ 90% for GdeltQuantitativeScorer
- Edge cases handled (missing data, out-of-range values)
- Real-world GDELT metadata examples tested

### Task 3: Verify with actual GDELT events
**Script:** Integration test using existing GDELT events from BigQuery

**Steps:**
1. Query 10-20 recent GDELT events from BigQuery
2. Score each event using GdeltQuantitativeScorer
3. Manually review scores for reasonableness
4. Verify high-risk events (negative Goldstein, CRISIS themes) score high
5. Verify low-risk events (positive Goldstein, no themes) score low

**Acceptance Criteria:**
- Scorer produces reasonable scores for real events
- High-risk events score ≥ 70
- Low-risk events score ≤ 40
- No crashes or errors on production data

## Verification Checklist

- [ ] GdeltQuantitativeScorer class created with all 4 scoring methods
- [ ] Weights configurable and validated (sum to 1.0)
- [ ] Goldstein scale inverted correctly (negative = high risk)
- [ ] Tone inverted correctly (negative = high risk)
- [ ] GKG themes scored categorically (CRISIS/PROTEST/CONFLICT)
- [ ] Theme intensity scored by frequency
- [ ] Weighted average aggregation implemented
- [ ] Unit tests pass with ≥90% coverage
- [ ] Integration test with real GDELT events passes
- [ ] Missing GKG data handled gracefully (neutral score)
- [ ] Scores clamped to 0-100 range

## Success Criteria

1. **Functional Scorer**: GdeltQuantitativeScorer computes 0-100 scores from GDELT metadata
2. **All 4 Signals Used**: Goldstein, tone, themes, intensity all weighted
3. **Configurable**: Weights can be adjusted for experimentation
4. **Well-Tested**: Unit tests verify correctness with edge cases
5. **Production-Ready**: Works with real GDELT events from BigQuery
6. **Ready for Integration**: Task 23-02 can import and use scorer in intelligence pipeline

## Next Steps (Task 23-02)

After completing this task:
1. Integrate GdeltQuantitativeScorer into intelligence pipeline
2. Modify LLM prompt to include GDELT quantitative score
3. Implement weighted combination of GDELT + LLM scores
4. Update `risk_score` and `severity` fields with hybrid results
5. Replace old LLM-only pipeline

## Dependencies

**Python Packages:**
- `scikit-learn >= 1.7.1` (MinMaxScaler)
- `numpy >= 1.24.0` (weighted average)

**Verify in requirements.txt:**
```bash
grep -E "(scikit-learn|numpy)" backend/requirements.txt
```

If missing, add:
```
scikit-learn>=1.7.1
numpy>=1.24.0
```

## Estimated Effort

- **Task 1 (Scorer implementation)**: 2-3 hours
- **Task 2 (Unit tests)**: 1-2 hours
- **Task 3 (Integration verification)**: 1 hour
- **Total**: 4-6 hours

## References

- **23-CONTEXT.md**: User vision for hybrid scoring
- **23-RESEARCH.md**: Standard libraries and patterns for GDELT scoring
- **Phase 22-02 Summary**: GdeltAdapter implementation (metadata structure)
- **GDELT Codebook**: http://data.gdeltproject.org/documentation/GDELT-Event_Codebook-V2.0.pdf
