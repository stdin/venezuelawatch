# Phase 23-02 Plan: Hybrid Intelligence Pipeline Integration

**Phase:** 23 - Intelligence Pipeline Rebuild
**Task:** 23-02 - Hybrid Scoring Integration
**Date:** 2026-01-10

## Objective

Integrate GdeltQuantitativeScorer into the intelligence pipeline and implement the hybrid scoring system that combines GDELT's quantitative signals with LLM's qualitative analysis using configurable weighted averaging.

## Context

From 23-CONTEXT.md:
- **Hybrid Scoring = Weighted Average of GDELT + LLM**
- **Configurable weights** (e.g., 70% LLM + 30% GDELT)
- **LLM sees GDELT score** in prompt for context-aware analysis
- **Process all events** (no filtering or threshold-based optimization)
- **Update risk_score and severity fields** with hybrid results
- **Replace immediately** (retire old LLM-only pipeline)

## Dependencies Met

✅ **Task 23-01 Complete**: GdeltQuantitativeScorer implemented and tested
✅ **Phase 7**: LLMIntelligence service exists with structured output
✅ **Phase 4**: risk_score (0-100) and severity (SEV1-5) fields defined

## Scope

### In Scope
1. Modify `LLMIntelligence.analyze_event_comprehensive()` to:
   - Compute GDELT quantitative score first
   - Include GDELT score in LLM prompt
   - Extract LLM's qualitative risk score
   - Combine scores using weighted average
2. Implement configurable weight ratio (via Django settings)
3. Update risk_score field with hybrid score (0-100)
4. Derive severity (SEV1-5) from hybrid score
5. Store final score in BigQuery event metadata
6. Unit and integration tests

### Out of Scope
- Frontend changes
- Historical score recalculation (admin feature for later)
- Score breakdown/audit trail fields
- Gradual rollout or A/B testing infrastructure
- Threshold-based processing optimization

## Technical Design

### Modified Files

```
backend/data_pipeline/services/
├── llm_intelligence.py  # MODIFIED: Add GDELT scoring integration
└── tests/
    └── test_hybrid_intelligence.py  # NEW: Integration tests

backend/venezuelawatch/
└── settings.py  # MODIFIED: Add hybrid scoring config
```

### Configuration (settings.py)

```python
# Hybrid intelligence scoring configuration
HYBRID_SCORING = {
    # Weight ratio for combining GDELT + LLM scores
    # Must sum to 1.0
    'weights': {
        'gdelt': 0.30,   # 30% quantitative signals
        'llm': 0.70,     # 70% qualitative analysis
    },

    # GDELT scorer signal weights
    'gdelt_weights': {
        'goldstein': 0.35,
        'tone': 0.25,
        'themes': 0.25,
        'intensity': 0.15,
    },

    # Severity thresholds (hybrid score → SEV1-5)
    'severity_thresholds': {
        'SEV5': 80,  # Critical: ≥80
        'SEV4': 60,  # High: 60-79
        'SEV3': 40,  # Medium: 40-59
        'SEV2': 20,  # Low: 20-39
        'SEV1': 0,   # Minimal: 0-19
    }
}
```

### Core Implementation

**Modified: `LLMIntelligence.analyze_event_comprehensive()`**

```python
# Add imports at top of llm_intelligence.py
from data_pipeline.services.gdelt_quantitative_scorer import GdeltQuantitativeScorer
from django.conf import settings

class LLMIntelligence:
    """Comprehensive intelligence analysis using hybrid GDELT + LLM scoring."""

    CACHE_TTL = 86400

    # Initialize GDELT scorer (class-level, reuse across calls)
    _gdelt_scorer = None

    @classmethod
    def get_gdelt_scorer(cls):
        """Get or create GDELT scorer with configured weights."""
        if cls._gdelt_scorer is None:
            weights = settings.HYBRID_SCORING.get('gdelt_weights')
            cls._gdelt_scorer = GdeltQuantitativeScorer(weights=weights)
        return cls._gdelt_scorer

    @classmethod
    def analyze_event_comprehensive(
        cls,
        title: str,
        content: str,
        context: Optional[Dict[str, Any]] = None,
        model: str = "fast"
    ) -> Dict[str, Any]:
        """
        Perform comprehensive intelligence analysis with hybrid scoring.

        Now computes hybrid risk score combining GDELT quantitative signals
        with LLM qualitative analysis using configurable weights.

        Args:
            title: Event title
            content: Event content
            context: Optional context (must include 'metadata' for GDELT scoring)
            model: Model tier ("fast", "standard", "premium")

        Returns:
            Intelligence analysis dict with hybrid risk score
        """
        # Check cache first
        cache_key = f"llm_intelligence:{hash(title + content + str(context) + model)}"
        cached_result = cache.get(cache_key)
        if cached_result:
            logger.info("Using cached LLM intelligence result")
            return cached_result

        # Step 1: Compute GDELT quantitative score
        gdelt_score = None
        if context and 'metadata' in context:
            try:
                scorer = cls.get_gdelt_scorer()
                gdelt_score = scorer.score_event(context['metadata'])
                logger.info(f"GDELT quantitative score: {gdelt_score:.2f}")
            except Exception as e:
                logger.warning(f"GDELT scoring failed, proceeding with LLM-only: {e}")
                gdelt_score = None

        # Select model based on tier
        model_name = {
            "fast": LLMClient.FAST_MODEL,
            "standard": LLMClient.PRIMARY_MODEL,
            "premium": LLMClient.PREMIUM_MODEL
        }.get(model, LLMClient.PRIMARY_MODEL)

        # Define JSON schema for structured response
        schema = cls._get_intelligence_schema()

        # Build comprehensive analysis prompt (includes GDELT score)
        system_prompt = cls._build_system_prompt()
        user_prompt = cls._build_analysis_prompt(
            title, content, context, gdelt_score=gdelt_score
        )

        try:
            import time
            start_time = time.time()

            # Use structured output method with JSON schema
            response = LLMClient._call_llm_structured(
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                schema=schema,
                schema_name="intelligence_analysis",
                model=model_name,
                temperature=0.3,
                max_tokens=2048,
                strict=True
            )

            processing_time = int((time.time() - start_time) * 1000)

            # Response is already parsed as dict from structured output
            result = response['content']

            # Step 2: Extract LLM qualitative risk score
            llm_risk_score = result['risk']['score'] * 100  # Convert 0-1 to 0-100

            # Step 3: Compute hybrid score using weighted average
            if gdelt_score is not None:
                weights = settings.HYBRID_SCORING['weights']
                hybrid_score = (
                    weights['gdelt'] * gdelt_score +
                    weights['llm'] * llm_risk_score
                )
                logger.info(
                    f"Hybrid score: {hybrid_score:.2f} "
                    f"(GDELT={gdelt_score:.2f} × {weights['gdelt']}, "
                    f"LLM={llm_risk_score:.2f} × {weights['llm']})"
                )
            else:
                # Fallback to LLM-only if GDELT scoring failed
                hybrid_score = llm_risk_score
                logger.warning("Using LLM-only score (GDELT unavailable)")

            # Step 4: Derive severity from hybrid score
            severity = cls._derive_severity(hybrid_score)

            # Update result with hybrid scoring
            result['risk']['score'] = hybrid_score / 100  # Store as 0-1 for consistency
            result['risk']['hybrid_score'] = hybrid_score  # Also store 0-100 version
            result['risk']['gdelt_score'] = gdelt_score
            result['risk']['llm_score'] = llm_risk_score
            result['risk']['severity'] = severity

            # Add metadata
            result['metadata'] = {
                'model_used': response['model'],
                'tokens_used': response['usage']['total_tokens'],
                'processing_time_ms': processing_time,
                'used_native_schema': model_name in [LLMClient.PRIMARY_MODEL, LLMClient.PREMIUM_MODEL],
                'scoring_method': 'hybrid' if gdelt_score is not None else 'llm_only'
            }

            # Cache result
            cache.set(cache_key, result, cls.CACHE_TTL)

            logger.info(
                f"Intelligence analysis complete: "
                f"hybrid_score={hybrid_score:.2f}, "
                f"severity={severity}, "
                f"sentiment={result['sentiment']['score']:.2f}, "
                f"entities={len(result['entities']['people']) + len(result['entities']['organizations'])}, "
                f"tokens={response['usage']['total_tokens']}, "
                f"time={processing_time}ms"
            )

            return result

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON response: {e}")
            return cls._get_fallback_result(title, content, f"JSON parse error: {str(e)}")

        except Exception as e:
            logger.error(f"LLM intelligence analysis failed: {e}", exc_info=True)
            return cls._get_fallback_result(title, content, str(e))

    @classmethod
    def _derive_severity(cls, hybrid_score: float) -> str:
        """
        Derive SEV1-5 severity level from hybrid risk score.

        Args:
            hybrid_score: Hybrid score (0-100)

        Returns:
            Severity level: SEV1, SEV2, SEV3, SEV4, or SEV5
        """
        thresholds = settings.HYBRID_SCORING['severity_thresholds']

        if hybrid_score >= thresholds['SEV5']:
            return 'SEV5'  # Critical
        elif hybrid_score >= thresholds['SEV4']:
            return 'SEV4'  # High
        elif hybrid_score >= thresholds['SEV3']:
            return 'SEV3'  # Medium
        elif hybrid_score >= thresholds['SEV2']:
            return 'SEV2'  # Low
        else:
            return 'SEV1'  # Minimal

    @classmethod
    def _build_analysis_prompt(
        cls,
        title: str,
        content: str,
        context: Optional[Dict[str, Any]],
        gdelt_score: Optional[float] = None
    ) -> str:
        """
        Build user prompt for analysis (now includes GDELT score).

        Args:
            title: Event title
            content: Event content
            context: Optional context
            gdelt_score: Optional GDELT quantitative score (0-100)

        Returns:
            Analysis prompt with GDELT context
        """
        context_str = ""
        if context:
            context_parts = []
            if 'source' in context:
                context_parts.append(f"Source: {context['source']}")
            if 'event_type' in context:
                context_parts.append(f"Event Type: {context['event_type']}")
            if 'timestamp' in context:
                context_parts.append(f"Date: {context['timestamp']}")

            if context_parts:
                context_str = f"\n\nContext:\n" + "\n".join(f"- {part}" for part in context_parts)

        # Add GDELT quantitative score to prompt
        gdelt_str = ""
        if gdelt_score is not None:
            gdelt_str = f"""

**GDELT Quantitative Signals:**
The GDELT database has computed a quantitative risk score for this event based on:
- Goldstein scale (cooperation/conflict indicator)
- Tone/sentiment analysis
- Presence of CRISIS/PROTEST/CONFLICT themes
- Theme intensity

GDELT Risk Score: {gdelt_score:.1f}/100

You should consider this quantitative assessment alongside your qualitative analysis.
You may agree, disagree, or refine it based on the full context and nuances in the text."""

        # Limit content to 5000 chars
        content_truncated = content[:5000] if len(content) > 5000 else content

        return f"""Analyze this event and provide comprehensive intelligence:

**Title:** {title}

**Content:** {content_truncated}{context_str}{gdelt_str}

Provide your analysis in the exact JSON format specified in the system prompt."""
```

### Backward Compatibility

**Existing Event Analysis Flow:**
1. Cloud Function syncs GDELT events → BigQuery
2. Pub/Sub triggers LLM analysis
3. `analyze_event_comprehensive()` called with event data
4. **NEW**: GDELT score computed from metadata
5. **NEW**: GDELT score included in LLM prompt
6. **NEW**: LLM score + GDELT score combined via weighted average
7. **UPDATED**: Hybrid score stored in `risk_score` field
8. **UPDATED**: Severity derived from hybrid score

**No Breaking Changes:**
- Same function signature for `analyze_event_comprehensive()`
- `context` parameter already accepts metadata
- Return format extends existing structure (backward compatible)
- Fallback to LLM-only if GDELT scoring fails

## Implementation Tasks

### Task 1: Add hybrid scoring configuration
**File:** `backend/venezuelawatch/settings.py`

**Steps:**
1. Add `HYBRID_SCORING` configuration dict
2. Set default weights: 70% LLM, 30% GDELT
3. Define severity thresholds (SEV1-5 ranges)
4. Configure GDELT scorer signal weights

**Acceptance Criteria:**
- Configuration loaded successfully
- Weights sum to 1.0
- Severity thresholds cover entire 0-100 range

### Task 2: Integrate GDELT scorer into LLMIntelligence
**File:** `backend/data_pipeline/services/llm_intelligence.py`

**Steps:**
1. Import GdeltQuantitativeScorer and settings
2. Add `get_gdelt_scorer()` class method
3. Modify `analyze_event_comprehensive()`:
   - Compute GDELT score from event metadata
   - Pass GDELT score to `_build_analysis_prompt()`
   - Extract LLM qualitative score from response
   - Compute weighted average hybrid score
   - Derive severity from hybrid score
   - Update result dict with hybrid fields
4. Add `_derive_severity()` helper method
5. Modify `_build_analysis_prompt()` to include GDELT score
6. Handle missing metadata gracefully (fallback to LLM-only)

**Acceptance Criteria:**
- GDELT scorer initialized with configured weights
- GDELT score computed for events with metadata
- LLM sees GDELT score in prompt
- Hybrid score = weighted average of GDELT + LLM
- Severity correctly derived from hybrid score
- Fallback to LLM-only if GDELT unavailable
- Logging shows GDELT, LLM, and hybrid scores

### Task 3: Write integration tests
**File:** `backend/data_pipeline/services/tests/test_hybrid_intelligence.py`

**Steps:**
1. Test hybrid scoring with realistic GDELT metadata
2. Test GDELT score included in LLM prompt
3. Test weighted average calculation
4. Test severity derivation (all 5 levels)
5. Test fallback to LLM-only (missing metadata)
6. Test configurable weights affect final score
7. Mock LLM responses to control test scenarios

**Acceptance Criteria:**
- All tests pass
- Coverage ≥ 85% for modified code
- Test high-risk event → SEV4/SEV5
- Test low-risk event → SEV1/SEV2
- Test weight configuration changes results

### Task 4: Update existing tests
**File:** `backend/data_pipeline/services/tests/test_llm_intelligence.py`

**Steps:**
1. Update existing tests to provide metadata in context
2. Verify backward compatibility (tests still pass)
3. Add test cases for new hybrid fields in response

**Acceptance Criteria:**
- All existing tests still pass
- No breaking changes to API
- Hybrid fields present in responses

### Task 5: Integration verification
**Manual Testing:**

**Steps:**
1. Query recent GDELT event from BigQuery
2. Call `analyze_event_comprehensive()` with event data
3. Verify GDELT score computed
4. Verify hybrid score = weighted average
5. Verify severity matches hybrid score
6. Verify LLM prompt includes GDELT score
7. Compare hybrid results to old LLM-only results

**Acceptance Criteria:**
- Hybrid scoring works end-to-end
- Scores reasonable for test events
- Severity assignments make sense
- No errors or crashes

## Verification Checklist

- [ ] HYBRID_SCORING configuration added to settings.py
- [ ] GdeltQuantitativeScorer integrated into LLMIntelligence
- [ ] GDELT score computed from event metadata
- [ ] GDELT score included in LLM prompt
- [ ] LLM qualitative score extracted from response
- [ ] Weighted average hybrid score calculated
- [ ] Severity (SEV1-5) derived from hybrid score
- [ ] Result dict includes hybrid_score, gdelt_score, llm_score, severity
- [ ] Fallback to LLM-only when GDELT unavailable
- [ ] Integration tests pass
- [ ] Existing tests still pass (backward compatible)
- [ ] Manual verification with real events successful
- [ ] Logging shows scoring breakdown

## Success Criteria

1. **Hybrid Scoring Works**: GDELT + LLM scores combined via weighted average
2. **LLM Context-Aware**: Prompt includes GDELT score for informed analysis
3. **Configurable Weights**: Can adjust GDELT/LLM ratio via settings
4. **Severity Updated**: SEV1-5 derived from hybrid score
5. **Backward Compatible**: Existing code/tests work without changes
6. **Production-Ready**: Works with real GDELT events from pipeline
7. **Old Pipeline Replaced**: LLM-only approach retired in favor of hybrid

## Migration Notes

**Immediate Replacement (per 23-CONTEXT.md):**
- No gradual rollout or A/B testing
- All events immediately use hybrid scoring
- Old LLM-only pipeline retired

**Data Impact:**
- `risk_score` field: Now hybrid score (was LLM-only)
- `severity` field: Now derived from hybrid (was LLM-derived)
- New fields in result dict: `hybrid_score`, `gdelt_score`, `llm_score`
- No schema migration needed (same field types)

**Monitoring:**
- Log GDELT, LLM, and hybrid scores for all events
- Track scoring method (hybrid vs llm_only fallback)
- Monitor severity distribution changes

## Next Steps (Post-Phase 23)

After completing this task:
1. **Deploy to production** (Cloud Functions, intelligence pipeline)
2. **Monitor scoring results** (hybrid vs old LLM-only comparison)
3. **Tune weights if needed** (adjust GDELT/LLM ratio based on results)
4. **Admin recalculation feature** (Phase 24: recompute scores for historical events)

## Dependencies

**Python Packages:**
- All satisfied by Task 23-01 (scikit-learn, numpy)

**Django Settings:**
- New HYBRID_SCORING configuration required

**Phase Dependencies:**
- Task 23-01 (GdeltQuantitativeScorer)
- Phase 7 (LLMIntelligence service)
- Phase 22 (GdeltAdapter metadata structure)

## Estimated Effort

- **Task 1 (Settings config)**: 30 minutes
- **Task 2 (LLMIntelligence integration)**: 3-4 hours
- **Task 3 (Integration tests)**: 2-3 hours
- **Task 4 (Update existing tests)**: 1 hour
- **Task 5 (Manual verification)**: 1 hour
- **Total**: 7.5-9.5 hours

## References

- **23-CONTEXT.md**: User decisions on hybrid scoring approach
- **23-01-PLAN.md**: GDELT quantitative scorer design
- **llm_intelligence.py**: Current LLM-only implementation
- **Phase 4 decisions**: risk_score (0-100) and severity (SEV1-5) definitions
