---
phase: 04-risk-intelligence-core
plan: 02
type: execute
---

<objective>
Upgrade risk scoring from single-dimensional (existing RiskScorer) to multi-dimensional aggregation combining LLM risk + sanctions + supply chain + urgency + sentiment.

Purpose: Produce more accurate composite risk scores that reflect multiple risk dimensions rather than keyword-based heuristics alone.
Output: Enhanced risk_scorer.py with weighted aggregation, risk_aggregator.py service, integrated into intelligence pipeline.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-risk-intelligence-core/04-RESEARCH.md
@.planning/phases/04-risk-intelligence-core/04-01-SUMMARY.md
@backend/data_pipeline/services/risk_scorer.py
@backend/data_pipeline/services/llm_intelligence.py
@backend/data_pipeline/services/sanctions_screener.py
@backend/data_pipeline/tasks/intelligence_tasks.py
@backend/core/models.py

**Tech stack available:**
- Existing RiskScorer with keyword/event-type/sentiment scoring
- LLM intelligence with risk scoring (llm_analysis['risk']['score'] 0.0-1.0)
- Sanctions screening from Plan 04-01 (0.0 or 1.0)
- Event model with sentiment, urgency, themes, risk_score fields

**Established patterns:**
- LLMIntelligence.analyze_event_comprehensive() returns structured analysis with risk dimension
- Celery tasks for async processing
- Event.llm_analysis JSONField stores complete LLM output

**Constraining decisions (from RESEARCH):**
- Use weighted aggregation pattern from ICRG/NCISS (not simple thresholds)
- Weights MUST sum to 1.0 exactly (avoid score inflation)
- Sanctions dimension highest weight (0.30-0.35) as binary flag
- Target median risk score ~30-40 (not >50 which indicates inflation)
- Scale final score to 0-100 for dashboard display

**Research findings:**
- Multi-dimensional risk aggregation is standard approach (ICRG 22 components, NCISS weighted scoring)
- Common pitfall: Risk score inflation (weights sum > 1.0, everything scores high)
- Common pitfall: Dimension correlation (sanctions + political risk often overlap)
- Pattern: Different weights by event_type (oil events emphasize supply chain, political events emphasize sanctions)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create risk_aggregator.py service with weighted multi-dimensional scoring</name>
  <files>backend/data_pipeline/services/risk_aggregator.py</files>
  <action>
    Create backend/data_pipeline/services/risk_aggregator.py implementing RiskAggregator class:

    ```python
    class RiskAggregator:
        """
        Multi-dimensional risk aggregation using weighted scoring.
        Follows NCISS/ICRG patterns for weighted arithmetic mean.
        """

        # Default weights (MUST sum to 1.0)
        DEFAULT_WEIGHTS = {
            'llm_base_risk': 0.25,      # LLM's risk assessment
            'sanctions': 0.30,           # Sanctions exposure (highest weight - binary)
            'sentiment': 0.20,           # Sentiment risk (negative = risky)
            'urgency': 0.15,             # Urgency level from LLM
            'supply_chain': 0.10,        # Supply chain impact
        }

        # Event-type-specific weight overrides
        EVENT_TYPE_WEIGHTS = {
            'TRADE': {
                'supply_chain': 0.25,    # Higher weight for trade events
                'sanctions': 0.35,
                'llm_base_risk': 0.20,
                'sentiment': 0.15,
                'urgency': 0.05,
            },
            'POLITICAL': {
                'sanctions': 0.40,       # Political events emphasize sanctions
                'llm_base_risk': 0.30,
                'sentiment': 0.20,
                'urgency': 0.10,
                'supply_chain': 0.00,    # Not relevant for pure political events
            },
            # Add more event types as needed
        }

        @classmethod
        def calculate_composite_risk(
            cls,
            llm_risk: float,
            sanctions_score: float,
            sentiment: float,
            urgency: str,
            event_type: str,
            themes: List[str]
        ) -> float:
            """
            Calculate composite risk score from multiple dimensions.

            Args:
                llm_risk: 0.0-1.0 from LLM analysis
                sanctions_score: 0.0 or 1.0 from sanctions screening
                sentiment: -1.0 to 1.0 (negative = risky)
                urgency: 'low', 'medium', 'high', 'immediate'
                event_type: Event type for weight selection
                themes: List of themes for supply chain detection

            Returns:
                Risk score 0-100
            """
            # Map urgency to risk score
            urgency_map = {'low': 0.2, 'medium': 0.5, 'high': 0.8, 'immediate': 1.0}
            urgency_risk = urgency_map.get(urgency, 0.5)

            # Map sentiment to risk (absolute value, negative = risky)
            sentiment_risk = abs(sentiment) if sentiment is not None else 0.5

            # Calculate supply chain risk from themes
            supply_chain_risk = cls._calculate_supply_chain_risk(themes)

            # Get weights for this event type (or default)
            weights = cls.EVENT_TYPE_WEIGHTS.get(event_type, cls.DEFAULT_WEIGHTS)

            # Weighted aggregation
            dimensions = {
                'llm_base_risk': llm_risk,
                'sanctions': sanctions_score,
                'sentiment': sentiment_risk,
                'urgency': urgency_risk,
                'supply_chain': supply_chain_risk,
            }

            composite = sum(
                dimensions[dim] * weights.get(dim, 0.0)
                for dim in dimensions
            )

            # Scale to 0-100
            return round(composite * 100, 2)

        @classmethod
        def _calculate_supply_chain_risk(cls, themes: List[str]) -> float:
            """Detect supply chain risk from event themes."""
            supply_chain_keywords = [
                'oil', 'export', 'trade', 'port', 'refinery', 'sanctions',
                'embargo', 'commodity', 'shipping', 'energy', 'petroleum'
            ]

            matches = sum(1 for keyword in supply_chain_keywords if keyword in ' '.join(themes).lower())

            if matches >= 3:
                return 0.8
            elif matches >= 2:
                return 0.6
            elif matches >= 1:
                return 0.4
            else:
                return 0.0
    ```

    **What to avoid and WHY:** Don't use simple thresholds (if risk > 0.7 then high). Multi-dimensional scoring captures nuance. Don't let weights sum to > 1.0 (causes score inflation).
  </action>
  <verify>python manage.py shell: from data_pipeline.services.risk_aggregator import RiskAggregator; score = RiskAggregator.calculate_composite_risk(llm_risk=0.7, sanctions_score=1.0, sentiment=-0.5, urgency='high', event_type='POLITICAL', themes=['sanctions', 'arrest']); assert 0 <= score <= 100; assert sum(RiskAggregator.DEFAULT_WEIGHTS.values()) == 1.0</verify>
  <done>risk_aggregator.py exists with RiskAggregator class, calculate_composite_risk() method returns 0-100 score, weights sum to 1.0, event-type-specific weights implemented, supply chain risk detection from themes working</done>
</task>

<task type="auto">
  <name>Task 2: Refactor risk_scorer.py to use RiskAggregator for multi-dimensional scoring</name>
  <files>backend/data_pipeline/services/risk_scorer.py</files>
  <action>
    Update backend/data_pipeline/services/risk_scorer.py to use new RiskAggregator:

    1. Keep existing RiskScorer class for backward compatibility but mark as deprecated

    2. Add new method calculate_comprehensive_risk() that uses RiskAggregator:
       ```python
       @classmethod
       def calculate_comprehensive_risk(cls, event: Event) -> float:
           """
           Calculate multi-dimensional risk score using RiskAggregator.
           Replaces legacy calculate_risk_score() method.
           """
           from data_pipeline.services.risk_aggregator import RiskAggregator
           from data_pipeline.services.sanctions_screener import SanctionsScreener

           # Extract dimensions from event
           llm_risk = event.llm_analysis.get('risk', {}).get('score', 0.5) if event.llm_analysis else 0.5
           sanctions_score = SanctionsScreener.screen_event_entities(event)
           sentiment = event.sentiment if event.sentiment is not None else 0.0
           urgency = event.urgency or 'medium'
           event_type = event.event_type or 'OTHER'
           themes = event.themes or []

           # Calculate composite risk
           composite_risk = RiskAggregator.calculate_composite_risk(
               llm_risk=llm_risk,
               sanctions_score=sanctions_score,
               sentiment=sentiment,
               urgency=urgency,
               event_type=event_type,
               themes=themes
           )

           return composite_risk
       ```

    3. Update calculate_risk_score() to call calculate_comprehensive_risk() instead of old logic

    **What to avoid and WHY:** Don't delete old RiskScorer code immediately (backward compatibility). New method coexists, becomes default path.
  </action>
  <verify>python manage.py shell: from core.models import Event; from data_pipeline.services.risk_scorer import RiskScorer; event = Event.objects.filter(llm_analysis__isnull=False).first(); score = RiskScorer.calculate_comprehensive_risk(event); assert 0 <= score <= 100</verify>
  <done>risk_scorer.py updated with calculate_comprehensive_risk() method, method uses RiskAggregator, old calculate_risk_score() refactored to call new method, backward compatibility maintained</done>
</task>

<task type="auto">
  <name>Task 3: Integrate multi-dimensional risk scoring into intelligence analysis pipeline</name>
  <files>backend/data_pipeline/tasks/intelligence_tasks.py, backend/data_pipeline/services/llm_intelligence.py</files>
  <action>
    Update intelligence analysis pipeline to calculate comprehensive risk scores:

    1. In backend/data_pipeline/tasks/intelligence_tasks.py, update analyze_event_intelligence() task:
       ```python
       # After LLM analysis completes and event.llm_analysis is populated
       from data_pipeline.services.risk_scorer import RiskScorer

       # Calculate comprehensive risk score (includes sanctions screening)
       comprehensive_risk = RiskScorer.calculate_comprehensive_risk(event)
       event.risk_score = comprehensive_risk
       event.save()
       ```

    2. Add batch risk recalculation for existing events:
       ```python
       @shared_task(bind=True, name='batch_recalculate_risk_scores')
       def batch_recalculate_risk_scores(self, lookback_days=30):
           """
           Recalculate risk scores for recent events using new multi-dimensional model.
           Useful after upgrading risk scoring logic.
           """
           cutoff_date = timezone.now() - timedelta(days=lookback_days)
           events = Event.objects.filter(
               created_at__gte=cutoff_date,
               llm_analysis__isnull=False
           )

           updated_count = 0
           for event in events:
               old_score = event.risk_score
               new_score = RiskScorer.calculate_comprehensive_risk(event)
               event.risk_score = new_score
               event.save()
               updated_count += 1

           return {"updated": updated_count}
       ```

    3. Register batch_recalculate_risk_scores in __init__.py

    **What to avoid and WHY:** Don't recalculate all historical events automatically (expensive). Provide manual batch task for controlled updates.
  </action>
  <verify>python manage.py shell: from data_pipeline.tasks.intelligence_tasks import batch_recalculate_risk_scores; result = batch_recalculate_risk_scores.delay(lookback_days=7); result.get(); assert result.result['updated'] > 0</verify>
  <done>intelligence_tasks.py updated to use calculate_comprehensive_risk(), risk scores calculated after LLM analysis, batch_recalculate_risk_scores task created for existing events, task registered in __init__.py</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] python manage.py check passes
- [ ] Test multi-dimensional scoring: Create test event with high sanctions score (1.0), high LLM risk (0.8), negative sentiment (-0.7), high urgency, verify composite score > 70
- [ ] Test weight validation: assert sum(RiskAggregator.DEFAULT_WEIGHTS.values()) == 1.0
- [ ] Test event-type-specific weights: Political event vs Trade event should use different weight distributions
- [ ] Run batch_recalculate_risk_scores on sample events, verify risk_score field updated
- [ ] Check risk score distribution: Median should be ~30-40, not >50 (avoid inflation)
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- RiskAggregator implements weighted multi-dimensional scoring
- Weights sum to 1.0 for all event types
- RiskScorer refactored to use RiskAggregator
- Intelligence pipeline calculates comprehensive risk scores
- Batch recalculation task available for existing events
- Risk scores scaled to 0-100
- No score inflation (median ~30-40)
</success_criteria>

<output>
After completion, create `.planning/phases/04-risk-intelligence-core/04-02-SUMMARY.md`:

# Phase 4 Plan 2: Multi-Dimensional Risk Aggregation Summary

**[Substantive one-liner - what shipped, not "phase complete"]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `path/to/file.ts` - Description
- `path/to/another.ts` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for 04-03-PLAN.md (Event Severity Classification)
</output>
