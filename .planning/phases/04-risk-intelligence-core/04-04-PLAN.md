---
phase: 04-risk-intelligence-core
plan: 04
type: execute
---

<objective>
Expose risk intelligence features via API for dashboard consumption and provide management commands for bulk operations.

Purpose: Enable Phase 5 dashboard to filter/sort events by risk score, severity, sanctions matches; provide admin tools for data management.
Output: Risk intelligence API endpoints, bulk recalculation management commands, dashboard integration documentation.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-risk-intelligence-core/04-RESEARCH.md
@.planning/phases/04-risk-intelligence-core/04-03-SUMMARY.md
@backend/venezuelawatch/api.py
@backend/data_pipeline/api.py
@backend/core/models.py
@backend/data_pipeline/tasks/intelligence_tasks.py

**Tech stack available:**
- django-ninja for REST API with auto OpenAPI docs
- Router pattern for API organization (established in Phase 1)
- Event model with risk_score, severity, sanctions_matches fields
- Celery tasks for async operations

**Established patterns:**
- API routers in app-level api.py (e.g., data_pipeline/api.py)
- Main NinjaAPI at venezuelawatch/api.py includes routers
- Typed request/response schemas with Pydantic
- Management commands in app/management/commands/

**Constraining decisions:**
- API should support filtering by: severity (SEV1-5), risk_score (range), has_sanctions_matches (boolean)
- Pagination required (could be 1000s of events)
- Sorting by: timestamp, risk_score, severity
- Sanctions match details included in event response if present

**Research findings:**
- Dashboard needs: High-risk event filtering, sanctions exposure visibility, severity-based prioritization
- Common use case: "Show SEV1-2 events with sanctions matches in last 30 days"
- Performance consideration: risk_score and severity indexed for fast filtering
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create risk intelligence API endpoints in data_pipeline/api.py</name>
  <files>backend/data_pipeline/api.py, backend/data_pipeline/schemas.py</files>
  <action>
    1. Create response schemas in backend/data_pipeline/schemas.py:
       ```python
       from ninja import Schema
       from typing import List, Optional
       from datetime import datetime

       class SanctionsMatchSchema(Schema):
           entity_name: str
           entity_type: str
           sanctions_list: str
           match_score: float

       class RiskIntelligenceEventSchema(Schema):
           id: str
           source: str
           event_type: str
           timestamp: datetime
           title: str
           summary: Optional[str]
           risk_score: Optional[float]
           severity: Optional[str]
           urgency: Optional[str]
           sentiment: Optional[float]
           themes: List[str]
           sanctions_matches: List[SanctionsMatchSchema]
           entities: dict  # {people: [], organizations: [], locations: []}

       class EventFilterParams(Schema):
           severity: Optional[str] = None  # e.g., "SEV1_CRITICAL,SEV2_HIGH"
           min_risk_score: Optional[float] = None
           max_risk_score: Optional[float] = None
           has_sanctions: Optional[bool] = None
           event_type: Optional[str] = None
           source: Optional[str] = None
           days_back: int = 30
           limit: int = 100
           offset: int = 0
       ```

    2. Add risk intelligence endpoints to backend/data_pipeline/api.py:
       ```python
       from ninja import Router
       from data_pipeline.schemas import RiskIntelligenceEventSchema, EventFilterParams, SanctionsMatchSchema
       from core.models import Event, SanctionsMatch

       risk_router = Router(tags=["Risk Intelligence"])

       @risk_router.get("/events", response=List[RiskIntelligenceEventSchema])
       def get_risk_intelligence_events(request, filters: EventFilterParams = None):
           """
           Get events with risk intelligence filtering and sorting.

           Filters:
           - severity: Comma-separated SEV levels (e.g., "SEV1_CRITICAL,SEV2_HIGH")
           - min_risk_score, max_risk_score: Risk score range (0-100)
           - has_sanctions: Boolean - only events with sanctions matches
           - event_type, source: Filter by type/source
           - days_back: Lookback period (default 30 days)

           Sorting: By risk_score DESC, timestamp DESC
           """
           cutoff_date = timezone.now() - timedelta(days=filters.days_back)
           queryset = Event.objects.filter(timestamp__gte=cutoff_date)

           # Apply filters
           if filters.severity:
               severity_levels = filters.severity.split(',')
               queryset = queryset.filter(severity__in=severity_levels)

           if filters.min_risk_score is not None:
               queryset = queryset.filter(risk_score__gte=filters.min_risk_score)

           if filters.max_risk_score is not None:
               queryset = queryset.filter(risk_score__lte=filters.max_risk_score)

           if filters.has_sanctions:
               queryset = queryset.filter(sanctions_matches__isnull=False).distinct()

           if filters.event_type:
               queryset = queryset.filter(event_type=filters.event_type)

           if filters.source:
               queryset = queryset.filter(source=filters.source)

           # Sort by risk_score DESC, timestamp DESC
           queryset = queryset.order_by('-risk_score', '-timestamp')

           # Pagination
           queryset = queryset[filters.offset:filters.offset + filters.limit]

           # Prefetch sanctions matches
           queryset = queryset.prefetch_related('sanctions_matches')

           return queryset

       @risk_router.get("/sanctions-summary", response=dict)
       def get_sanctions_summary(request, days_back: int = 30):
           """
           Get summary of sanctions matches in recent events.

           Returns:
           {
               "total_events_with_sanctions": int,
               "unique_sanctioned_entities": int,
               "by_entity_type": {"person": X, "organization": Y},
               "by_sanctions_list": {"OFAC-SDN": X, "UN-1267": Y}
           }
           """
           cutoff_date = timezone.now() - timedelta(days=days_back)
           matches = SanctionsMatch.objects.filter(event__timestamp__gte=cutoff_date)

           return {
               "total_events_with_sanctions": matches.values('event').distinct().count(),
               "unique_sanctioned_entities": matches.values('entity_name').distinct().count(),
               "by_entity_type": dict(matches.values('entity_type').annotate(count=Count('id'))),
               "by_sanctions_list": dict(matches.values('sanctions_list').annotate(count=Count('id')))
           }
       ```

    3. Include risk_router in main API (backend/venezuelawatch/api.py or data_pipeline/api.py main router)

    **What to avoid and WHY:** Don't fetch all events then filter in Python (slow). Use Django ORM filters for database-level filtering with indexes.
  </action>
  <verify>curl http://localhost:8000/api/risk/events?severity=SEV1_CRITICAL,SEV2_HIGH&has_sanctions=true returns JSON array of events, curl http://localhost:8000/api/risk/sanctions-summary returns summary dict, visit http://localhost:8000/api/docs shows risk intelligence endpoints documented</verify>
  <done>data_pipeline/schemas.py has response schemas, data_pipeline/api.py has risk intelligence endpoints with filtering/sorting, sanctions summary endpoint implemented, router included in main API, OpenAPI docs auto-generated</done>
</task>

<task type="auto">
  <name>Task 2: Create management commands for bulk risk intelligence operations</name>
  <files>backend/data_pipeline/management/commands/recalculate_risk.py, backend/data_pipeline/management/commands/classify_all_severity.py</files>
  <action>
    1. Create backend/data_pipeline/management/commands/recalculate_risk.py:
       ```python
       from django.core.management.base import BaseCommand
       from core.models import Event
       from data_pipeline.services.risk_scorer import RiskScorer
       from datetime import timedelta
       from django.utils import timezone

       class Command(BaseCommand):
           help = 'Recalculate risk scores for events using multi-dimensional model'

           def add_arguments(self, parser):
               parser.add_argument(
                   '--days',
                   type=int,
                   default=30,
                   help='Lookback period in days (default: 30)'
               )
               parser.add_argument(
                   '--all',
                   action='store_true',
                   help='Recalculate ALL events (ignores --days)'
               )

           def handle(self, *args, **options):
               if options['all']:
                   queryset = Event.objects.filter(llm_analysis__isnull=False)
                   self.stdout.write('Recalculating risk for ALL events...')
               else:
                   cutoff_date = timezone.now() - timedelta(days=options['days'])
                   queryset = Event.objects.filter(
                       created_at__gte=cutoff_date,
                       llm_analysis__isnull=False
                   )
                   self.stdout.write(f'Recalculating risk for events in last {options["days"]} days...')

               total = queryset.count()
               updated = 0

               for event in queryset.iterator(chunk_size=100):
                   old_score = event.risk_score
                   new_score = RiskScorer.calculate_comprehensive_risk(event)
                   event.risk_score = new_score
                   event.save(update_fields=['risk_score'])
                   updated += 1

                   if updated % 100 == 0:
                       self.stdout.write(f'Progress: {updated}/{total}')

               self.stdout.write(self.style.SUCCESS(f'Successfully updated {updated} events'))
       ```

    2. Create backend/data_pipeline/management/commands/classify_all_severity.py (similar pattern for severity classification)

    3. Create backend/data_pipeline/management/commands/intelligence_stats.py:
       ```python
       class Command(BaseCommand):
           help = 'Display risk intelligence statistics'

           def handle(self, *args, **options):
               from core.models import Event, SanctionsMatch

               total_events = Event.objects.count()
               events_with_risk = Event.objects.filter(risk_score__isnull=False).count()
               events_with_severity = Event.objects.filter(severity__isnull=False).count()
               events_with_sanctions = Event.objects.filter(sanctions_matches__isnull=False).distinct().count()

               self.stdout.write('\n=== Risk Intelligence Statistics ===\n')
               self.stdout.write(f'Total events: {total_events}')
               self.stdout.write(f'Events with risk scores: {events_with_risk} ({events_with_risk/total_events*100:.1f}%)')
               self.stdout.write(f'Events with severity: {events_with_severity} ({events_with_severity/total_events*100:.1f}%)')
               self.stdout.write(f'Events with sanctions matches: {events_with_sanctions} ({events_with_sanctions/total_events*100:.1f}%)')

               # Severity distribution
               self.stdout.write('\n--- Severity Distribution ---')
               for severity in ['SEV1_CRITICAL', 'SEV2_HIGH', 'SEV3_MEDIUM', 'SEV4_LOW', 'SEV5_MINIMAL']:
                   count = Event.objects.filter(severity=severity).count()
                   self.stdout.write(f'{severity}: {count}')

               # Risk score percentiles
               self.stdout.write('\n--- Risk Score Distribution ---')
               from django.db.models import Avg, Max, Min, StdDev
               stats = Event.objects.filter(risk_score__isnull=False).aggregate(
                   avg=Avg('risk_score'),
                   max=Max('risk_score'),
                   min=Min('risk_score'),
                   stddev=StdDev('risk_score')
               )
               self.stdout.write(f'Average: {stats["avg"]:.2f}')
               self.stdout.write(f'Min: {stats["min"]:.2f}, Max: {stats["max"]:.2f}')
               self.stdout.write(f'Std Dev: {stats["stddev"]:.2f}')
       ```

    **What to avoid and WHY:** Don't load all events into memory (queryset.iterator() with chunking prevents OOM). Don't update entire model (update_fields=['risk_score'] for performance).
  </action>
  <verify>python manage.py recalculate_risk --days 7 runs successfully and shows progress, python manage.py classify_all_severity --days 7 runs successfully, python manage.py intelligence_stats displays statistics without errors</verify>
  <done>recalculate_risk.py command created with --days and --all options, classify_all_severity.py command created, intelligence_stats.py command created for monitoring, all commands use iterator() for memory efficiency</done>
</task>

<task type="auto">
  <name>Task 3: Create dashboard integration documentation</name>
  <files>backend/docs/risk-intelligence-api.md, backend/README.md</files>
  <action>
    Create backend/docs/risk-intelligence-api.md documenting risk intelligence features for Phase 5 dashboard:

    ```markdown
    # Risk Intelligence API Documentation

    Phase 4 Risk Intelligence Core provides multi-dimensional risk analysis for Venezuela events.

    ## Features

    ### 1. Multi-Dimensional Risk Scoring (0-100)

    Risk scores combine 5 dimensions:
    - **LLM Base Risk** (25% weight): Claude's risk assessment from event content
    - **Sanctions** (30% weight): Binary flag if event mentions sanctioned entities
    - **Sentiment** (20% weight): Negative sentiment = higher risk
    - **Urgency** (15% weight): Immediate > High > Medium > Low
    - **Supply Chain** (10% weight): Keywords indicating trade/oil/export disruption

    Weights vary by event type:
    - Political events emphasize sanctions (40%)
    - Trade events emphasize supply chain (25%)

    ### 2. Severity Classification (SEV 1-5)

    NCISS-style multi-criteria assessment:
    - **SEV1 - Critical**: International scope, permanent/long-term, irreversible, major economic impact
    - **SEV2 - High**: National scope, months duration, difficult to reverse, significant impact
    - **SEV3 - Medium**: National scope, weeks duration, moderate reversibility/impact
    - **SEV4 - Low**: Local scope, days duration, easily reversed, minimal impact
    - **SEV5 - Minimal**: Local scope, hours duration, negligible impact

    Severity = impact magnitude (independent of probability)
    Risk = probability × impact (composite score)

    ### 3. Sanctions Screening

    - Automatic fuzzy matching against OpenSanctions/OFAC lists
    - Matches threshold 0.7+ flagged as sanctioned
    - Daily refresh to catch new sanctions additions
    - Tracks: entity name, type (person/organization), sanctions list, match confidence

    ## API Endpoints

    ### GET /api/risk/events

    Filter and retrieve events with risk intelligence.

    **Query Parameters:**
    - `severity` (string): Comma-separated SEV levels (e.g., "SEV1_CRITICAL,SEV2_HIGH")
    - `min_risk_score` (float): Minimum risk score (0-100)
    - `max_risk_score` (float): Maximum risk score (0-100)
    - `has_sanctions` (boolean): Filter to events with sanctions matches
    - `event_type` (string): Filter by event type
    - `source` (string): Filter by data source
    - `days_back` (int): Lookback period in days (default: 30)
    - `limit` (int): Page size (default: 100, max: 1000)
    - `offset` (int): Pagination offset (default: 0)

    **Response:** Array of RiskIntelligenceEventSchema

    **Example:**
    ```bash
    # Get high-severity events with sanctions in last 7 days
    curl "http://localhost:8000/api/risk/events?severity=SEV1_CRITICAL,SEV2_HIGH&has_sanctions=true&days_back=7"

    # Get high-risk political events
    curl "http://localhost:8000/api/risk/events?min_risk_score=70&event_type=POLITICAL"
    ```

    ### GET /api/risk/sanctions-summary

    Get aggregate statistics on sanctions matches.

    **Query Parameters:**
    - `days_back` (int): Lookback period (default: 30)

    **Response:**
    ```json
    {
      "total_events_with_sanctions": 15,
      "unique_sanctioned_entities": 8,
      "by_entity_type": {"person": 5, "organization": 3},
      "by_sanctions_list": {"OFAC-SDN": 6, "UN-1267": 2}
    }
    ```

    ## Management Commands

    ### Recalculate Risk Scores

    ```bash
    # Recalculate last 30 days
    python manage.py recalculate_risk

    # Recalculate last 90 days
    python manage.py recalculate_risk --days 90

    # Recalculate ALL events
    python manage.py recalculate_risk --all
    ```

    ### Classify Severity

    ```bash
    python manage.py classify_all_severity --days 30
    ```

    ### View Statistics

    ```bash
    python manage.py intelligence_stats
    ```

    ## Dashboard Integration (Phase 5)

    ### Recommended Filters

    1. **Crisis Dashboard**: severity=SEV1_CRITICAL,SEV2_HIGH + has_sanctions=true
    2. **High Risk Feed**: min_risk_score=70 + days_back=7
    3. **Sanctions Monitor**: has_sanctions=true + all event types
    4. **Supply Chain Risk**: event_type=TRADE + min_risk_score=50

    ### Performance Notes

    - `risk_score` and `severity` are indexed for fast filtering
    - Use pagination (limit/offset) for large result sets
    - Prefetch sanctions_matches included automatically
    ```

    Update backend/README.md with link to risk-intelligence-api.md in "Documentation" section.

    **What to avoid and WHY:** Don't write generic docs ("API returns events"). Provide specific examples, use cases, and performance guidance for Phase 5 dashboard developers.
  </action>
  <verify>cat backend/docs/risk-intelligence-api.md shows documentation with API endpoints, examples, management commands; grep "risk-intelligence-api.md" backend/README.md finds reference</verify>
  <done>risk-intelligence-api.md created with comprehensive API documentation, usage examples, dashboard integration guidance, management command reference, performance notes, README.md updated with link</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] python manage.py check passes
- [ ] API test: curl /api/risk/events?severity=SEV1_CRITICAL returns filtered events
- [ ] API test: curl /api/risk/sanctions-summary returns statistics
- [ ] Visit http://localhost:8000/api/docs shows risk intelligence endpoints in OpenAPI docs
- [ ] Management command test: python manage.py recalculate_risk --days 7 executes without errors
- [ ] Management command test: python manage.py intelligence_stats displays statistics
- [ ] Documentation complete: risk-intelligence-api.md covers all endpoints, examples, dashboard guidance
</verification>

<success_criteria>

- All tasks completed
- All verification checks pass
- Risk intelligence API endpoints implemented with filtering/sorting
- Sanctions summary endpoint provides aggregate statistics
- Management commands created for bulk operations
- API uses pagination for performance
- OpenAPI documentation auto-generated
- Dashboard integration documentation complete with examples
- Phase 4 complete - ready for Phase 5 dashboard integration
</success_criteria>

<output>
After completion, create `.planning/phases/04-risk-intelligence-core/04-04-SUMMARY.md`:

# Phase 4 Plan 4: Risk Intelligence API & Dashboard Integration Summary

**[Substantive one-liner - what shipped, not "phase complete"]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `path/to/file.ts` - Description
- `path/to/another.ts` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Phase Complete

**Phase 4: Risk Intelligence Core** is complete.

All risk intelligence infrastructure working:
- ✅ Sanctions screening with OpenSanctions/OFAC API integration (Plan 04-01)
- ✅ Multi-dimensional risk aggregation (5 dimensions, weighted scoring) (Plan 04-02)
- ✅ Event severity classification (SEV 1-5 using NCISS pattern) (Plan 04-03)
- ✅ Risk intelligence API endpoints and management commands (Plan 04-04)

**Risk intelligence now providing:**
1. Composite risk scores (0-100) from LLM + sanctions + sentiment + urgency + supply chain
2. Severity classification (SEV1-5) for dashboard prioritization
3. Sanctions exposure tracking with fuzzy entity matching
4. API filtering by risk score, severity, sanctions matches
5. Daily sanctions refresh and bulk recalculation tools

**Ready for next phase**: Phase 5 - Dashboard & Events Feed (real-time event aggregation, filtering, search, risk visualization)
</output>
