---
phase: 27-small-scale-end-to-end-pipeline-test-in-gcp
plan: 03
type: execute
---

<objective>
Validate the complete intelligence pipeline end-to-end: verify that ingested events trigger processing (risk scoring, entity extraction, graph generation) and data appears correctly in the frontend.

Purpose: Prove the full data flow works from ingestion to visualization without manual intervention.
Output: Confirmed operational intelligence pipeline with risk scores, entities, and graphs visible in frontend dashboard.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-phase.md
./summary.md
~/.claude/get-shit-done/references/checkpoints.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/27-small-scale-end-to-end-pipeline-test-in-gcp/27-CONTEXT.md
@.planning/phases/27-small-scale-end-to-end-pipeline-test-in-gcp/27-01-SUMMARY.md
@.planning/phases/27-small-scale-end-to-end-pipeline-test-in-gcp/27-02-SUMMARY.md

# Intelligence pipeline architecture
@.planning/phases/18-gcp-native-pipeline-migration/18-02-SUMMARY.md
@.planning/phases/23-intelligence-pipeline-rebuild/23-02-SUMMARY.md
@docs/ARCHITECTURE.md

# Entity graphs
@.planning/phases/26-gkg-theme-population-entity-relationship-graphs-event-lineage-tracking/26-04-SUMMARY.md

**Processing flow (from Phase 18):**
1. Event ingestion → Pub/Sub event-created topic
2. Pub/Sub → Cloud Run extract-entities handler
3. Pub/Sub → Cloud Tasks analyze-intelligence queue
4. Cloud Tasks → Cloud Run LLM analysis handler
5. Results written back to BigQuery metadata fields

**Expected outputs:**
- Events have risk_score and severity populated
- Entity mentions extracted and linked
- Entity graphs queryable via API
- Frontend dashboard displays events, risk scores, entity profiles
</context>

<tasks>

<task type="auto">
  <name>Task 1: Verify intelligence processing pipeline operational</name>
  <files>N/A (Pub/Sub, Cloud Tasks, BigQuery inspection)</files>
  <action>Verify that ingested events triggered downstream processing. Check: (1) Pub/Sub metrics - gcloud pubsub topics list-subscriptions event-created to confirm subscriptions active, check message delivery count, (2) Cloud Run logs - gcloud run services logs read venezuelawatch-api --filter="resource.labels.service_name=venezuelawatch-api" for entity extraction and risk calculation invocations, (3) Cloud Tasks queue - gcloud tasks queues describe llm-analysis-queue to see task execution count, (4) BigQuery metadata - SELECT event_id, metadata.risk_score, metadata.severity, metadata.llm_analysis FROM `venezuelawatch_analytics.events` WHERE source_name='gdelt' AND metadata.risk_score IS NOT NULL LIMIT 10 to verify processing completed. Expect to see risk scores and severity populated for at least some events (LLM analysis may be async and slower).</action>
  <verify>BigQuery shows events with populated risk_score and severity, Cloud Run/Tasks logs show processing activity</verify>
  <done>Intelligence processing pipeline operational, events have risk scores and severity classifications</done>
</task>

<task type="auto">
  <name>Task 2: Test entity extraction and graph generation</name>
  <files>N/A (BigQuery queries, API testing)</files>
  <action>Verify entity extraction and graph functionality. Check: (1) Entity mentions - SELECT COUNT(*) FROM `venezuelawatch_analytics.entity_mentions` WHERE event_id IN (SELECT event_id FROM `venezuelawatch_analytics.events` WHERE source_name='gdelt' LIMIT 100) to confirm entities extracted from ingested events, (2) Test entity API endpoint - curl {CLOUD_RUN_URL}/api/entities?limit=10 to verify entity list returns, (3) Test graph API - curl {CLOUD_RUN_URL}/api/graph/entities?entity_id={sample_entity_id}&time_range=30d to verify graph generation works, (4) Check for entity linking - verify metadata.linked_entities populated in events (Phase 24 entity resolution). Document entity count and sample API responses.</action>
  <verify>Entity mentions in BigQuery, entity API returns data, graph API returns nodes/edges JSON</verify>
  <done>Entity extraction working, entities queryable via API, graph generation operational</done>
</task>

<task type="auto">
  <name>Task 3: Validate frontend data visualization</name>
  <files>frontend/ (local dev server)</files>
  <action>Start frontend development server and test data visualization. Run: cd frontend && npm run dev, then update frontend/.env with VITE_API_URL={CLOUD_RUN_URL}. Navigate to: (1) Dashboard (http://localhost:5173/) - verify events appear in EventList, check that risk scores and severity badges display correctly, (2) Entity pages (http://localhost:5173/entities) - verify entity leaderboard populates, click entity to view profile with linked events, (3) Graph page (http://localhost:5173/graph) - select an entity and verify relationship graph renders with nodes/edges, (4) Chat interface (http://localhost:5173/chat) - test a query like "What are the highest risk events?" to verify tool calls work with GCP backend. Take screenshots or document observed behavior.</action>
  <verify>Frontend dev server starts, all pages load without errors, data displays correctly from GCP backend</verify>
  <done>Frontend successfully visualizes data from GCP backend, all features functional</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete end-to-end pipeline from GDELT ingestion to frontend visualization</what-built>
  <how-to-verify>
    1. Start frontend: npm run dev (ensure VITE_API_URL points to Cloud Run)
    2. Visit Dashboard: Verify events display with risk scores and severity badges
    3. Visit Entities: Verify entity leaderboard shows entities from ingested events
    4. Visit Graph: Select an entity and verify relationship graph renders
    5. Test Chat: Ask "Show me the highest risk events" and verify tool results display
    6. Check for errors: Open browser console, verify no API errors or failed requests
    7. Confirm: Full data flow working (GDELT → BigQuery → processing → API → frontend)
  </how-to-verify>
  <resume-signal>Type "approved" if full pipeline working, or describe issues found</resume-signal>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] Events have risk_score and severity populated in BigQuery
- [ ] Entity mentions extracted and queryable
- [ ] Graph API returns valid nodes/edges
- [ ] Frontend displays events, entities, and graphs correctly
- [ ] No errors in browser console or API logs
</verification>

<success_criteria>

- All tasks completed
- Full pipeline validated by user
- Data flows from ingestion to frontend without errors
- All intelligence features operational (risk scoring, entities, graphs)
- Phase 27 complete - GCP deployment ready for expansion
</success_criteria>

<output>
After completion, create `.planning/phases/27-small-scale-end-to-end-pipeline-test-in-gcp/27-03-SUMMARY.md`:

# Phase 27 Plan 03: End-to-End Intelligence Pipeline Validation Summary

**[One-liner describing successful end-to-end validation]**

## Accomplishments

- Verified intelligence processing pipeline operational
- Validated entity extraction and graph generation
- Confirmed frontend visualization working with GCP backend
- Proved complete data flow from ingestion to UI

## Files Created/Modified

[Frontend .env updated with Cloud Run URL, or "None"]

## Decisions Made

[Any configuration or deployment decisions, or "None"]

## Issues Encountered

[Pipeline issues and resolutions, or "None"]

## Next Phase Readiness

**Phase 27 Complete** - Small-scale end-to-end test successful. GCP deployment validated, ready for:
- Expanding to larger datasets (months of historical data)
- Enabling all Cloud Scheduler jobs for continuous ingestion
- Production launch preparation

**Post-Test Path (from CONTEXT.md):**
- ✅ Small test succeeded
- Next: Expand to larger datasets
- Then: Production deployment
</output>
