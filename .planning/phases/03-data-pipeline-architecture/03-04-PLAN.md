---
phase: 03-data-pipeline-architecture
plan: 04
subsystem: data-ingestion
tags: [un-comtrade, world-bank, trade-data, batch-ingestion, monthly-quarterly]

requires:
  - phase: 03-01
    provides: Celery infrastructure, BaseIngestionTask, Secret Manager integration
  - phase: 01-04
    provides: Event model with TimescaleDB hypertables
  - phase: discovery
    provides: UN Comtrade + World Bank API characteristics

provides:
  - UN Comtrade trade data ingestion (monthly)
  - World Bank development indicators ingestion (quarterly)
  - Trade flow tracking (imports/exports by commodity)
  - Development metrics for Venezuela context
  - Monthly/quarterly batch scheduling

affects: [04-risk-intelligence, 05-dashboard]

tech-stack:
  patterns: [batch-ingestion, pagination, trade-data, development-indicators]
  libraries: [comtradeapicall, wbgapi, pandas, tenacity]

confidence: medium-high
estimated-completion: 20 min
---

# Plan 03-04: Monthly/Quarterly Ingestion (UN Comtrade + World Bank)

**Implement monthly/quarterly batch ingestion of UN Comtrade trade data and World Bank development indicators with pagination, rate limiting, and trade flow tracking**

## Context

UN Comtrade and World Bank provide essential trade and development data for Venezuela intelligence:

**UN Comtrade (United Nations International Trade Statistics):**
- Source: UN Statistics Division
- Authentication: Optional API key (free registration)
- Rate limit: 500 requests/day (100/hour without key)
- Update frequency: Monthly (with 2-3 month lag)
- Python library: comtradeapicall (community wrapper)
- Format: JSON/CSV with trade flows (imports/exports by commodity)
- Venezuela code: ISO3 = VEN (862)

**World Bank Indicators:**
- Source: World Bank Open Data
- Authentication: None required
- Rate limit: Auto-chunked (generous, undocumented)
- Update frequency: Quarterly to annual
- Python library: wbgapi (official wrapper)
- Format: pandas DataFrame with multi-index (country, year, indicator)
- Venezuela code: VE

**Key Use Cases:**
- Track Venezuela oil exports (HS code 2709: Petroleum oils)
- Monitor import dependencies (food, medicine, machinery)
- Identify trade partners and shifting alliances
- Track development metrics (poverty rate, electricity access, etc.)
- Detect trade disruptions from sanctions or political events

## Goals

1. Install comtradeapicall and wbgapi libraries
2. Create UN Comtrade ingestion task for Venezuela trade flows
3. Create World Bank ingestion task for development indicators
4. Implement pagination for large trade datasets
5. Define commodity codes and indicators to track
6. Schedule monthly/quarterly batch ingestion
7. Verify trade data retrieval and storage

## Non-Goals

- Trade network analysis or partner ranking (deferred to Phase 4)
- Commodity price correlation analysis (keep simple)
- Tariff or trade policy tracking (out of scope)
- Forecasting trade flows (deferred to analytics phase)

## Tasks

### Task 1: Install libraries and configure UN Comtrade API

**Install packages:**
```bash
cd backend
pip install comtradeapicall==1.5.0 wbgapi==1.0.12 pandas==2.2.3
pip freeze | grep -E "comtradeapicall|wbgapi|pandas" >> requirements.txt
```

**Set UN Comtrade API key (optional but recommended):**
```bash
# Register at https://comtradeplus.un.org/
# Store in Secret Manager
python manage.py set_secret api-comtrade-key "YOUR_COMTRADE_API_KEY"
```

**Create Comtrade client wrapper:**
- File: `backend/data_pipeline/services/comtrade_client.py`
- Import: `from comtradeapicall import comtradeapicall; from data_pipeline.services.secrets import SecretManagerClient`
- Class: `ComtradeClient`
- Method: `__init__(self)` - get API key from Secret Manager (optional)
- Method: `get_trade_data(reporter: str = 'VEN', period: str = None, commodity: str = 'TOTAL') -> pd.DataFrame`
- Method: `get_imports(period: str, commodity: str) -> pd.DataFrame`
- Method: `get_exports(period: str, commodity: str) -> pd.DataFrame`
- Handle rate limiting with tenacity (500 req/day = ~20/hour)

**Define commodity codes to track:**
- File: `backend/data_pipeline/config/comtrade_config.py`
- Dictionary: `VENEZUELA_COMMODITIES`
  ```python
  VENEZUELA_COMMODITIES = {
      '2709': {'name': 'Petroleum oils (crude)', 'category': 'energy'},
      '2710': {'name': 'Petroleum oils (refined)', 'category': 'energy'},
      '1001': {'name': 'Wheat', 'category': 'food'},
      '1005': {'name': 'Maize (corn)', 'category': 'food'},
      '3004': {'name': 'Medicaments', 'category': 'healthcare'},
      '8471': {'name': 'Computing machinery', 'category': 'technology'},
      'TOTAL': {'name': 'All commodities', 'category': 'total_trade'},
  }
  ```

**Test Comtrade connection:**
```python
from data_pipeline.services.comtrade_client import ComtradeClient
client = ComtradeClient()
df = client.get_exports(period='2023', commodity='2709')  # Venezuela oil exports
print(df.head())
```

**Commit:**
```
feat(03-04): install UN Comtrade libraries and configure API client

Task 1: Install libraries and configure UN Comtrade API
- Install comtradeapicall==1.5.0, wbgapi==1.0.12, pandas==2.2.3
- Create ComtradeClient wrapper with Secret Manager integration
- Implement get_trade_data(), get_imports(), get_exports() methods
- Define VENEZUELA_COMMODITIES tracking list (oil, food, medicine, tech)
- Configure rate limiting for 500 req/day quota
- Set api-comtrade-key in Secret Manager (optional)
- Verify Comtrade API connection with test query
```

### Task 2: Create UN Comtrade ingestion task

**Create Comtrade ingestion task:**
- File: `backend/data_pipeline/tasks/comtrade_tasks.py`
- Import: `from data_pipeline.services.comtrade_client import ComtradeClient; from data_pipeline.config.comtrade_config import VENEZUELA_COMMODITIES`
- Create `@shared_task(base=BaseIngestionTask, bind=True)` decorator
- Function: `ingest_comtrade_trade_data(self, period: str = None, lookback_months: int = 3)`
- If period is None, use previous month (e.g., if today is 2024-03-15, use 2024-02)
- Fetch trade data for each commodity in VENEZUELA_COMMODITIES
- Create Events for significant trade flows (imports/exports)
- Return: `{'commodities_processed': count, 'trade_flows_created': count}`

**Map trade data to Events:**
- File: `backend/data_pipeline/services/event_mapper.py` (add function)
- Function: `map_comtrade_to_event(trade_record: dict, commodity_info: dict) -> Event`
- Map fields:
  - source = 'comtrade'
  - event_type = 'trade_flow'
  - title = f"{commodity_info['name']}: {flow_type} ${value:,.0f}" (e.g., "Petroleum oils (crude): Exports $2.5B")
  - content = f"Venezuela {flow_type} {quantity} units of {commodity} to/from {partner} in {period}"
  - location = 'Venezuela'
  - timestamp = period end date (e.g., 2024-02-29)
  - metadata = {commodity_code, partner_country, trade_value_usd, quantity, flow_type, period}
  - url = Comtrade data URL (if available)

**Filter significant trade flows:**
- Only create Events for trade flows > $10M USD (configurable threshold)
- Reduces noise from minor transactions
- Focuses on material trade relationships

**Add deduplication:**
- Use Event.objects.filter(source='comtrade', metadata__period=period, metadata__commodity_code=code, metadata__partner_country=partner).exists()

**Implement pagination:**
- Comtrade API may return large datasets
- Use comtradeapicall's built-in pagination handling
- Process results in batches of 100 records

**Verification:**
```python
from data_pipeline.tasks.comtrade_tasks import ingest_comtrade_trade_data
result = ingest_comtrade_trade_data.delay(period='2023')
result.get(timeout=300)  # May take several minutes
```

**Commit:**
```
feat(03-04): create UN Comtrade trade data ingestion task

Task 2: Create UN Comtrade ingestion task
- Create ingest_comtrade_trade_data task with monthly period
- Fetch imports/exports for Venezuela commodities (oil, food, medicine, tech)
- Map trade flows to Event model (source='comtrade', event_type='trade_flow')
- Filter for significant trade flows (> $10M USD)
- Implement pagination for large datasets
- Add deduplication by period + commodity + partner
- Return commodities_processed and trade_flows_created metrics
```

### Task 3: Create World Bank development indicators ingestion task

**Create World Bank client wrapper:**
- File: `backend/data_pipeline/services/worldbank_client.py`
- Import: `import wbgapi as wb`
- Class: `WorldBankClient`
- Method: `get_indicator(indicator_id: str, country: str = 'VE', start_year: int = None) -> pd.DataFrame`
- Method: `get_latest_value(indicator_id: str, country: str = 'VE') -> dict`
- No authentication needed for World Bank API

**Define indicators to track:**
- File: `backend/data_pipeline/config/worldbank_config.py`
- Dictionary: `VENEZUELA_INDICATORS`
  ```python
  VENEZUELA_INDICATORS = {
      'NY.GDP.MKTP.CD': {'name': 'GDP (current USD)', 'category': 'economic'},
      'FP.CPI.TOTL.ZG': {'name': 'Inflation (CPI)', 'category': 'economic'},
      'SL.UEM.TOTL.ZS': {'name': 'Unemployment rate', 'category': 'labor'},
      'SI.POV.NAHC': {'name': 'Poverty headcount ratio', 'category': 'social'},
      'EG.ELC.ACCS.ZS': {'name': 'Electricity access (%)', 'category': 'infrastructure'},
      'SP.POP.TOTL': {'name': 'Population total', 'category': 'demographic'},
      'SE.XPD.TOTL.GD.ZS': {'name': 'Education expenditure (% GDP)', 'category': 'social'},
      'SH.XPD.CHEX.GD.ZS': {'name': 'Health expenditure (% GDP)', 'category': 'social'},
  }
  ```

**Create World Bank ingestion task:**
- File: `backend/data_pipeline/tasks/worldbank_tasks.py`
- Import: `from data_pipeline.services.worldbank_client import WorldBankClient; from data_pipeline.config.worldbank_config import VENEZUELA_INDICATORS`
- Create `@shared_task(base=BaseIngestionTask, bind=True)` decorator
- Function: `ingest_worldbank_indicators(self, lookback_years: int = 2)`
- Fetch latest values for all indicators in VENEZUELA_INDICATORS
- Create Events for each indicator observation
- Return: `{'indicators_processed': count, 'observations_created': count}`

**Map World Bank data to Events:**
- File: `backend/data_pipeline/services/event_mapper.py` (add function)
- Function: `map_worldbank_to_event(indicator_data: dict, indicator_info: dict) -> Event`
- Map fields:
  - source = 'worldbank'
  - event_type = 'development_indicator'
  - title = f"{indicator_info['name']}: {value}" (e.g., "GDP (current USD): $98.4B")
  - content = f"Venezuela's {indicator_name} for {year}: {value} {units}"
  - location = 'Venezuela'
  - timestamp = year end date (e.g., 2023-12-31)
  - metadata = {indicator_id, indicator_name, year, value, category}
  - url = World Bank data URL

**Add deduplication:**
- Use Event.objects.filter(source='worldbank', metadata__indicator_id=indicator_id, metadata__year=year).exists()

**Handle missing data:**
- World Bank data often has gaps for Venezuela (especially recent years)
- Log warning if no data available for indicator
- Continue processing other indicators

**Verification:**
```python
from data_pipeline.tasks.worldbank_tasks import ingest_worldbank_indicators
result = ingest_worldbank_indicators.delay()
result.get(timeout=120)
```

**Commit:**
```
feat(03-04): create World Bank development indicators ingestion task

Task 3: Create World Bank development indicators ingestion task
- Create WorldBankClient with get_indicator() and get_latest_value() methods
- Define VENEZUELA_INDICATORS tracking list (GDP, inflation, poverty, etc.)
- Create ingest_worldbank_indicators task with 2-year lookback
- Map indicator observations to Event model (source='worldbank', event_type='development_indicator')
- Handle missing data gracefully (log warning, continue)
- Add deduplication by indicator_id + year
- Return indicators_processed and observations_created metrics
```

### Task 4: Schedule monthly/quarterly ingestion with Celery Beat

**Update Celery Beat schedule:**
- File: `backend/config/settings.py`
- Add to CELERY_BEAT_SCHEDULE:
  ```python
  'ingest-comtrade-trade-data': {
      'task': 'data_pipeline.tasks.comtrade_tasks.ingest_comtrade_trade_data',
      'schedule': 2592000.0,  # Monthly (30 days in seconds)
      'kwargs': {'lookback_months': 3},  # Catch delayed updates
  },
  'ingest-worldbank-indicators': {
      'task': 'data_pipeline.tasks.worldbank_tasks.ingest_worldbank_indicators',
      'schedule': 7776000.0,  # Quarterly (90 days in seconds)
      'kwargs': {'lookback_years': 2},
  },
  ```

**Create Cloud Scheduler jobs:**
```bash
# UN Comtrade ingestion (monthly on 1st day at 2 AM UTC)
gcloud scheduler jobs create http comtrade-ingestion \
  --location=us-central1 \
  --schedule="0 2 1 * *" \
  --time-zone="UTC" \
  --uri="https://venezuelawatch-api.run.app/api/tasks/trigger/comtrade" \
  --http-method=POST \
  --oidc-service-account-email=venezuelawatch-scheduler@venezuelawatch-staging.iam.gserviceaccount.com \
  --headers="Content-Type=application/json" \
  --message-body='{"lookback_months": 3}' \
  --project=venezuelawatch-staging

# World Bank ingestion (quarterly on 1st day of Jan/Apr/Jul/Oct at 3 AM UTC)
gcloud scheduler jobs create http worldbank-ingestion \
  --location=us-central1 \
  --schedule="0 3 1 1,4,7,10 *" \
  --time-zone="UTC" \
  --uri="https://venezuelawatch-api.run.app/api/tasks/trigger/worldbank" \
  --http-method=POST \
  --oidc-service-account-email=venezuelawatch-scheduler@venezuelawatch-staging.iam.gserviceaccount.com \
  --headers="Content-Type=application/json" \
  --message-body='{"lookback_years": 2}' \
  --project=venezuelawatch-staging
```

**Add trigger endpoints:**
- File: `backend/data_pipeline/api.py`
- Add routes:
  - `@router.post('/trigger/comtrade')`
  - `@router.post('/trigger/worldbank')`
- Dispatch tasks with provided parameters

**Create management commands for manual backfill:**
- File: `backend/data_pipeline/management/commands/backfill_comtrade.py`
- Command: `python manage.py backfill_comtrade --period 2020-01 --commodity 2709`
- File: `backend/data_pipeline/management/commands/backfill_worldbank.py`
- Command: `python manage.py backfill_worldbank --start-year 2015 --end-year 2023`

**Update README:**
- Add Comtrade and World Bank to ingestion workflow
- Document manual backfill commands

**Commit:**
```
feat(03-04): schedule monthly/quarterly ingestion with Celery Beat

Task 4: Schedule monthly/quarterly ingestion with Celery Beat
- Add ingest-comtrade-trade-data to CELERY_BEAT_SCHEDULE (monthly)
- Add ingest-worldbank-indicators to CELERY_BEAT_SCHEDULE (quarterly)
- Create Cloud Scheduler jobs (comtrade monthly 1st @ 2AM, worldbank quarterly 1st @ 3AM)
- Add /api/tasks/trigger/comtrade and /api/tasks/trigger/worldbank endpoints
- Create backfill_comtrade and backfill_worldbank management commands
- Update README with manual ingestion instructions
```

### checkpoint:human-verify

**Verify the following:**

1. **UN Comtrade API connection works:**
   ```python
   from data_pipeline.services.comtrade_client import ComtradeClient
   client = ComtradeClient()
   df = client.get_exports(period='2023', commodity='2709')
   print(df.head())  # Should see Venezuela oil export data
   ```

2. **World Bank API connection works:**
   ```python
   from data_pipeline.services.worldbank_client import WorldBankClient
   client = WorldBankClient()
   data = client.get_latest_value('NY.GDP.MKTP.CD', country='VE')
   print(data)  # Should see Venezuela GDP
   ```

3. **Comtrade ingestion task works:**
   ```python
   from data_pipeline.tasks.comtrade_tasks import ingest_comtrade_trade_data
   result = ingest_comtrade_trade_data.delay(period='2023')
   result.get(timeout=300)
   # Should return {'commodities_processed': X, 'trade_flows_created': Y}
   ```

4. **World Bank ingestion task works:**
   ```python
   from data_pipeline.tasks.worldbank_tasks import ingest_worldbank_indicators
   result = ingest_worldbank_indicators.delay()
   result.get(timeout=120)
   # Should return {'indicators_processed': X, 'observations_created': Y}
   ```

5. **Trade flow Events created:**
   ```python
   from events.models import Event
   Event.objects.filter(source='comtrade', event_type='trade_flow').count()
   # Should be > 0

   # Check oil exports
   oil_exports = Event.objects.filter(source='comtrade', metadata__commodity_code='2709')
   print(oil_exports.first().title)  # Should see "Petroleum oils (crude): Exports $X.XB"
   ```

6. **Development indicator Events created:**
   ```python
   Event.objects.filter(source='worldbank', event_type='development_indicator').count()
   # Should be > 0

   # Check GDP
   gdp_events = Event.objects.filter(source='worldbank', metadata__indicator_id='NY.GDP.MKTP.CD')
   print(gdp_events.first().title)  # Should see "GDP (current USD): $XX.XB"
   ```

7. **Celery Beat schedules updated:**
   ```bash
   celery -A config beat --loglevel=info
   # Should see comtrade and worldbank tasks in scheduled tasks
   ```

8. **Cloud Scheduler jobs created:**
   ```bash
   gcloud scheduler jobs list --location=us-central1
   # Should see comtrade-ingestion and worldbank-ingestion
   ```

9. **Rate limiting works:**
   ```python
   # Run comtrade task multiple times and verify no rate limit errors
   # Monitor Celery logs for retry behavior
   ```

**Type "approved" to continue or describe any issues.**

## Verification Criteria

- [ ] UN Comtrade API key stored in Secret Manager and retrieved
- [ ] ComtradeClient connects and fetches Venezuela trade data
- [ ] World Bank API client retrieves development indicators
- [ ] VENEZUELA_COMMODITIES and VENEZUELA_INDICATORS registries defined
- [ ] Comtrade ingestion creates trade_flow Events (filtered > $10M)
- [ ] World Bank ingestion creates development_indicator Events
- [ ] Deduplication prevents duplicate trade flows and indicators
- [ ] Pagination handles large Comtrade datasets
- [ ] Celery Beat schedules monthly/quarterly ingestion
- [ ] Cloud Scheduler jobs created for production
- [ ] Manual backfill commands work for historical data

## Dependencies

**Python packages:**
- comtradeapicall==1.5.0
- wbgapi==1.0.12
- pandas==2.2.3
- tenacity==9.0.0 (from Plan 03-02)

**External APIs:**
- UN Comtrade API (optional API key recommended)
- World Bank Open Data API (no auth required)

**GCP resources:**
- Cloud Scheduler jobs: comtrade-ingestion (monthly), worldbank-ingestion (quarterly)
- Secret Manager: api-comtrade-key (optional)
- Service account: venezuelawatch-scheduler (from Plan 03-02)

**Requires:**
- Plan 03-01 complete (Celery + Redis + Secret Manager)
- Event model with TimescaleDB (Plan 01-04)

## Risks

1. **Comtrade data lag**: Trade data has 2-3 month lag. Don't expect current month data.
2. **Comtrade rate limits**: 500 req/day with key, 100/day without. Monthly batch should be safe, but backfills could exhaust quota.
3. **Venezuela data availability**: Both Comtrade and World Bank may have sparse Venezuela data due to political/reporting issues.
4. **API deprecation**: comtradeapicall is community-maintained. World Bank wbgapi is official but API could change.
5. **Large datasets**: Fetching all Venezuela trade flows could be thousands of records. Pagination and filtering (> $10M) help.

## Rollback Plan

If major issues occur:
1. Disable Cloud Scheduler: `gcloud scheduler jobs pause comtrade-ingestion worldbank-ingestion --location=us-central1`
2. Remove CELERY_BEAT_SCHEDULE entries for comtrade and worldbank
3. Delete Events: `Event.objects.filter(source__in=['comtrade', 'worldbank']).delete()`
4. Delete tasks: `rm backend/data_pipeline/tasks/comtrade_tasks.py worldbank_tasks.py`
5. Uninstall: `pip uninstall comtradeapicall wbgapi`

## Next Steps

After this plan completes:
- **Phase 3 complete** - All 7 data sources ingesting (GDELT, ReliefWeb, FRED, Comtrade, World Bank)
- **Phase 4: Risk Intelligence Core** - Build risk scoring engine on top of ingested data
- **Phase 5: Dashboard & Events Feed** - Visualize trade flows, economic indicators, and news events
- **Future enhancement**: Add USITC and Port Authority data if needed (deferred from discovery)
