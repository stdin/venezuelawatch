---
phase: 03-data-pipeline-architecture
plan: 03
subsystem: data-ingestion
tags: [fred, economic-data, batch-ingestion, time-series, api-integration]

requires:
  - phase: 03-01
    provides: Celery infrastructure, BaseIngestionTask, Secret Manager integration
  - phase: 01-04
    provides: Event model with TimescaleDB hypertables
  - phase: discovery
    provides: FRED API characteristics and recommended series

provides:
  - FRED economic indicator ingestion (daily batch)
  - Time-series data storage for economic metrics
  - Venezuela-specific economic series tracking
  - Parallel series ingestion with rate limiting
  - Economic event generation from indicator changes

affects: [04-risk-intelligence, 05-dashboard]

tech-stack:
  patterns: [batch-ingestion, time-series, parallel-tasks, economic-indicators]
  libraries: [fredapi, pandas, tenacity]

confidence: high
estimated-completion: 18 min
---

# Plan 03-03: Daily Batch Ingestion (FRED Economic Data)

**Implement daily batch ingestion of FRED economic indicators with parallel series fetching, time-series storage, and economic event generation**

## Context

FRED (Federal Reserve Economic Data) provides critical economic indicators for Venezuela risk intelligence:

**FRED API Characteristics:**
- Source: Federal Reserve Bank of St. Louis
- Authentication: Free API key (register at research.stlouisfed.org)
- Rate limit: "Reasonable" (undocumented, but generous for daily batch)
- Update frequency: Daily to quarterly (depending on series)
- Python library: fredapi (official wrapper)
- Format: pandas DataFrame with date index + values

**Key Venezuela Economic Series:**
- Oil prices: DCOILWTICO (WTI Crude Oil)
- Inflation: FPCPITOTLZGVEN (CPI Year-over-Year)
- GDP: NYGDPPCAPKDVEN (GDP per capita)
- Exchange rates: DEXVZUS (Venezuela Bolivar / US Dollar)
- Unemployment: LRUNTTTTVEQ156S (Unemployment Rate)
- Reserves: TRESEGVEA634N (Total Reserves)

**Value Proposition:**
- Track macroeconomic trends affecting investment decisions
- Detect economic shocks (oil price crashes, hyperinflation spikes)
- Generate "economic events" when indicators cross thresholds
- Provide historical context for risk scoring

## Goals

1. Install fredapi and configure FRED API key via Secret Manager
2. Define Venezuela-relevant economic series to track
3. Create FRED ingestion task with parallel series fetching
4. Store time-series data in Event model with economic metadata
5. Implement threshold-based economic event generation
6. Schedule daily batch ingestion via Celery Beat
7. Verify historical data retrieval and daily updates

## Non-Goals

- Economic forecasting or trend prediction (deferred to Phase 4)
- Custom economic indicators or derived metrics (keep simple)
- Real-time economic data (FRED is batch-oriented)
- Charting or visualization (deferred to Phase 5: Dashboard)

## Tasks

### Task 1: Install fredapi and configure API key

**Install fredapi:**
```bash
cd backend
pip install fredapi==0.5.2 pandas==2.2.3
pip freeze | grep -E "fredapi|pandas" >> requirements.txt
```

**Set FRED API key in Secret Manager:**
```bash
# Get free API key from https://research.stlouisfed.org/useraccount/apikey
# Store in Secret Manager
python manage.py set_secret api-fred-key "YOUR_FRED_API_KEY_HERE"
```

**Create FRED client wrapper:**
- File: `backend/data_pipeline/services/fred_client.py`
- Import: `from fredapi import Fred; from data_pipeline.services.secrets import SecretManagerClient`
- Class: `FREDClient`
- Method: `__init__(self)` - get API key from Secret Manager, initialize Fred client
- Method: `get_series(series_id: str, start_date: str = None) -> pd.DataFrame`
- Method: `get_latest_observation(series_id: str) -> dict`
- Cache Fred client instance to avoid repeated Secret Manager calls

**Test FRED connection:**
```python
from data_pipeline.services.fred_client import FREDClient
client = FREDClient()
df = client.get_series('DCOILWTICO', start_date='2024-01-01')
print(df.head())  # Should see oil price data
```

**Commit:**
```
feat(03-03): install fredapi and configure Secret Manager integration

Task 1: Install fredapi and configure API key
- Install fredapi==0.5.2 and pandas==2.2.3
- Create FREDClient wrapper with Secret Manager integration
- Implement get_series() and get_latest_observation() methods
- Cache Fred client instance to avoid repeated API calls
- Set api-fred-key in Secret Manager
- Verify FRED API connection with test query
```

### Task 2: Define Venezuela economic series and create data model

**Create economic series registry:**
- File: `backend/data_pipeline/config/fred_series.py`
- Define Venezuela-relevant economic series:
  ```python
  VENEZUELA_ECONOMIC_SERIES = {
      'oil_prices': {
          'DCOILWTICO': {
              'name': 'WTI Crude Oil Price',
              'units': 'USD/barrel',
              'frequency': 'daily',
              'threshold_low': 50,  # Generate event if < $50
              'threshold_high': 100,  # Generate event if > $100
          },
          'DCOILBRENTEU': {
              'name': 'Brent Crude Oil Price',
              'units': 'USD/barrel',
              'frequency': 'daily',
              'threshold_low': 55,
              'threshold_high': 105,
          },
      },
      'venezuela_macro': {
          'FPCPITOTLZGVEN': {
              'name': 'Venezuela CPI Inflation (YoY)',
              'units': 'percent',
              'frequency': 'annual',
              'threshold_high': 100,  # Hyperinflation alert
          },
          'NYGDPPCAPKDVEN': {
              'name': 'Venezuela GDP per Capita',
              'units': 'constant 2015 USD',
              'frequency': 'annual',
          },
      },
      'exchange_rates': {
          'DEXVZUS': {
              'name': 'Venezuela Bolivar / USD',
              'units': 'VEF/USD',
              'frequency': 'daily',
              'note': 'May be discontinued due to hyperinflation',
          },
      },
      'reserves': {
          'TRESEGVEA634N': {
              'name': 'Venezuela Total Reserves',
              'units': 'USD',
              'frequency': 'monthly',
              'threshold_low': 10_000_000_000,  # $10B alert
          },
      },
  }
  ```

**Create EconomicSeries model (optional):**
- File: `backend/data_pipeline/models.py`
- Model: `EconomicSeries`
- Fields: series_id (CharField), category (CharField), name, units, frequency, last_updated, last_value, metadata (JSONField)
- Purpose: Track which series we're monitoring and their latest values
- Alternative: Just use Event model with event_type='economic_indicator'

**Decision:** Use Event model for simplicity (avoid new model for Phase 3)
- event_type = 'economic_indicator'
- title = series name (e.g., "WTI Crude Oil Price: $85.50")
- content = JSON with {series_id, value, units, previous_value, change_pct}
- timestamp = observation date
- metadata = full series config + observation details

**Commit:**
```
feat(03-03): define Venezuela economic series registry

Task 2: Define Venezuela economic series and create data model
- Create VENEZUELA_ECONOMIC_SERIES registry with oil prices, inflation, GDP, exchange rates, reserves
- Define threshold values for economic event generation
- Document series frequencies (daily, monthly, annual)
- Decide to use Event model for economic indicators (event_type='economic_indicator')
- Map economic observations to Event fields (title, content, timestamp, metadata)
```

### Task 3: Create FRED ingestion task with parallel series fetching

**Create FRED ingestion task:**
- File: `backend/data_pipeline/tasks/fred_tasks.py`
- Import: `from data_pipeline.services.fred_client import FREDClient; from data_pipeline.config.fred_series import VENEZUELA_ECONOMIC_SERIES`
- Create `@shared_task(base=BaseIngestionTask, bind=True)` decorator
- Function: `ingest_fred_series(self, lookback_days: int = 7)`
- Iterate through all series in VENEZUELA_ECONOMIC_SERIES
- For each series, fetch latest observations (last 7 days to catch updates)
- Create Event for each new observation
- Return: `{'series_ingested': count, 'observations_created': count}`

**Implement parallel series fetching:**
- Use Celery group to fetch multiple series in parallel:
  ```python
  from celery import group
  job = group(ingest_single_series.s(series_id) for series_id in all_series_ids)
  result = job.apply_async()
  ```
- Create helper task: `ingest_single_series(series_id: str, lookback_days: int = 7)`
- Each series is fetched by separate worker for parallelism

**Handle missing data gracefully:**
- Some series may be discontinued (e.g., DEXVZUS due to hyperinflation)
- Catch fredapi.exceptions.HTTPError and log warning
- Continue processing other series

**Add deduplication:**
- Use Event.objects.filter(source='fred', metadata__series_id=series_id, timestamp=observation_date).exists()
- Skip if observation already exists

**Verification:**
```python
from data_pipeline.tasks.fred_tasks import ingest_fred_series
result = ingest_fred_series.delay()
result.get(timeout=120)  # Should return {'series_ingested': X, 'observations_created': Y}
```

**Commit:**
```
feat(03-03): create FRED ingestion task with parallel fetching

Task 3: Create FRED ingestion task with parallel series fetching
- Create ingest_fred_series task with 7-day lookback
- Implement parallel series fetching using Celery groups
- Create ingest_single_series helper for individual series
- Handle missing/discontinued series gracefully (log warning, continue)
- Map FRED observations to Event model (source='fred', event_type='economic_indicator')
- Implement deduplication by series_id + observation date
- Return series_ingested and observations_created metrics
```

### Task 4: Implement threshold-based economic event generation

**Create threshold detection:**
- File: `backend/data_pipeline/services/economic_events.py`
- Function: `detect_threshold_events(series_id: str, current_value: float, previous_value: float, config: dict) -> list[dict]`
- Check if current_value crosses threshold_low or threshold_high
- Generate event with severity based on threshold type:
  - threshold_low breach: "Oil prices fall below $50/barrel" (severity: high)
  - threshold_high breach: "Hyperinflation exceeds 100% YoY" (severity: critical)
- Return list of event dicts to create

**Update ingestion task:**
- File: `backend/data_pipeline/tasks/fred_tasks.py`
- In `ingest_single_series`, after creating economic_indicator Event:
  - Get previous observation from database
  - Call `detect_threshold_events()`
  - Create additional Events for threshold breaches with event_type='economic_alert'

**Example threshold event:**
- event_type = 'economic_alert'
- title = "WTI Crude Oil Price Falls Below $50/barrel"
- content = "WTI crude oil dropped to $48.50, down 12% from previous week. This may signal economic headwinds for Venezuela's oil-dependent economy."
- severity = 'high'
- metadata = {series_id, threshold_breached, current_value, previous_value, change_pct}

**Test threshold detection:**
```python
from data_pipeline.services.economic_events import detect_threshold_events
config = {'threshold_low': 50, 'threshold_high': 100}
events = detect_threshold_events('DCOILWTICO', 48.5, 55.0, config)
# Should return 1 event for threshold_low breach
```

**Commit:**
```
feat(03-03): implement threshold-based economic event generation

Task 4: Implement threshold-based economic event generation
- Create detect_threshold_events() function to identify threshold breaches
- Generate economic_alert Events when series cross configured thresholds
- Set severity levels (high for threshold_low, critical for threshold_high)
- Generate descriptive titles and content for threshold events
- Integrate threshold detection into ingest_single_series task
- Verify threshold detection with test cases
```

### Task 5: Schedule daily FRED ingestion and add to Celery Beat

**Update Celery Beat schedule:**
- File: `backend/config/settings.py`
- Add to CELERY_BEAT_SCHEDULE:
  ```python
  'ingest-fred-economic-data': {
      'task': 'data_pipeline.tasks.fred_tasks.ingest_fred_series',
      'schedule': 86400.0,  # Daily at midnight
      'args': (7,),  # 7-day lookback to catch delayed updates
  }
  ```

**Create Cloud Scheduler job:**
```bash
gcloud scheduler jobs create http fred-ingestion \
  --location=us-central1 \
  --schedule="0 0 * * *" \
  --time-zone="America/New_York" \
  --uri="https://venezuelawatch-api.run.app/api/tasks/trigger/fred" \
  --http-method=POST \
  --oidc-service-account-email=venezuelawatch-scheduler@venezuelawatch-staging.iam.gserviceaccount.com \
  --headers="Content-Type=application/json" \
  --message-body='{"lookback_days": 7}' \
  --project=venezuelawatch-staging
```

**Add trigger endpoint:**
- File: `backend/data_pipeline/api.py`
- Add route: `@router.post('/trigger/fred')`
- Dispatch `ingest_fred_series.delay(lookback_days)`

**Create management command for manual backfill:**
- File: `backend/data_pipeline/management/commands/backfill_fred.py`
- Command: `python manage.py backfill_fred --start-date 2020-01-01 --end-date 2024-12-31`
- Useful for historical data ingestion
- Use lookback_days parameter or date range

**Update README:**
- Add FRED ingestion to development workflow
- Document how to manually trigger ingestion: `python manage.py backfill_fred`

**Commit:**
```
feat(03-03): schedule daily FRED ingestion with Celery Beat and Cloud Scheduler

Task 5: Schedule daily FRED ingestion and add to Celery Beat
- Add ingest-fred-economic-data to CELERY_BEAT_SCHEDULE (daily at midnight)
- Create Cloud Scheduler job for production (daily 00:00 EST)
- Add /api/tasks/trigger/fred endpoint
- Create backfill_fred management command for historical data
- Update README with manual ingestion instructions
```

### checkpoint:human-verify

**Verify the following:**

1. **FRED API connection works:**
   ```python
   from data_pipeline.services.fred_client import FREDClient
   client = FREDClient()
   df = client.get_series('DCOILWTICO', start_date='2024-01-01')
   print(df.tail())  # Should see recent oil prices
   ```

2. **FRED ingestion task works:**
   ```python
   from data_pipeline.tasks.fred_tasks import ingest_fred_series
   result = ingest_fred_series.delay()
   result.get(timeout=120)
   # Should return {'series_ingested': X, 'observations_created': Y}
   ```

3. **Economic indicator Events created:**
   ```python
   from events.models import Event
   Event.objects.filter(source='fred', event_type='economic_indicator').count()
   # Should be > 0

   # Check specific series
   oil_events = Event.objects.filter(source='fred', metadata__series_id='DCOILWTICO')
   print(oil_events.first().title)  # Should see "WTI Crude Oil Price: $XX.XX"
   ```

4. **Threshold detection works:**
   ```python
   # Manually test threshold detection
   from data_pipeline.services.economic_events import detect_threshold_events
   config = {'threshold_low': 50, 'name': 'WTI Crude Oil Price'}
   events = detect_threshold_events('DCOILWTICO', 48.0, 55.0, config)
   print(len(events))  # Should be 1 if threshold crossed
   ```

5. **Celery Beat schedule updated:**
   ```bash
   celery -A config beat --loglevel=info
   # Should see "ingest-fred-economic-data" in scheduled tasks
   ```

6. **Cloud Scheduler job created:**
   ```bash
   gcloud scheduler jobs describe fred-ingestion --location=us-central1
   # Should show schedule="0 0 * * *"
   ```

7. **Parallel series fetching works:**
   ```python
   # Check Celery worker logs for parallel task execution
   # Should see multiple "ingest_single_series" tasks running concurrently
   ```

**Type "approved" to continue or describe any issues.**

## Verification Criteria

- [ ] FRED API key stored in Secret Manager and retrieved successfully
- [ ] FREDClient connects to FRED API and fetches series data
- [ ] Venezuela economic series registry defined with thresholds
- [ ] FRED ingestion task creates economic_indicator Events
- [ ] Parallel series fetching works (Celery groups)
- [ ] Deduplication prevents duplicate observations
- [ ] Threshold detection generates economic_alert Events
- [ ] Celery Beat schedules daily ingestion
- [ ] Cloud Scheduler job created for production
- [ ] Manual backfill command works for historical data

## Dependencies

**Python packages:**
- fredapi==0.5.2
- pandas==2.2.3
- tenacity==9.0.0 (from Plan 03-02)

**External APIs:**
- FRED API (free API key required)
- API key stored in Secret Manager: api-fred-key

**GCP resources:**
- Cloud Scheduler job: fred-ingestion (daily at midnight EST)
- Service account: venezuelawatch-scheduler (from Plan 03-02)

**Requires:**
- Plan 03-01 complete (Celery + Redis + Secret Manager)
- Event model with TimescaleDB (Plan 01-04)

## Risks

1. **FRED series discontinuation**: Some Venezuela series (e.g., DEXVZUS) may be discontinued. Handle gracefully with warnings.
2. **Rate limiting**: FRED doesn't publish rate limits. Daily batch with 7-day lookback should be safe, but monitor for errors.
3. **Data lag**: FRED data can lag by days to months (especially for Venezuela). Don't expect real-time updates.
4. **Threshold tuning**: Initial thresholds (e.g., oil < $50) may need adjustment based on market conditions.
5. **Parallel task overhead**: Fetching 10+ series in parallel could overwhelm FRED API. Consider rate limiting if issues occur.

## Rollback Plan

If major issues occur:
1. Disable Cloud Scheduler: `gcloud scheduler jobs pause fred-ingestion --location=us-central1`
2. Remove CELERY_BEAT_SCHEDULE entry for fred ingestion
3. Delete FRED Events: `Event.objects.filter(source='fred').delete()`
4. Delete tasks: `rm backend/data_pipeline/tasks/fred_tasks.py`
5. Uninstall: `pip uninstall fredapi pandas`

## Next Steps

After this plan completes:
- **Plan 03-04**: Implement UN Comtrade + World Bank monthly/quarterly ingestion
- **Phase 4**: Build risk intelligence engine using GDELT, ReliefWeb, and FRED data
- **Phase 5**: Create dashboard to visualize economic indicators alongside news events
